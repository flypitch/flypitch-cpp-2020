%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[sigplan,10pt,review, anonymous]{acmart}

\usepackage{cleveref}

% note(jesse, October 01 2019, 04:00 PM): I'm getting weird typesetting authors when the `anonymous' option is removed

% add: anonymous
\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan]{acmart}\settopmatter{}

%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[CPP'20]{The 9th ACM SIGPLAN International Conference on Certified Programs and Proofs}{January 20--21, 2020}{New Orleans, LA, USA}
\acmYear{2020}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%\citestyle{acmauthoryear}  %% For author/year citations
%\citestyle{acmnumeric}     %% For numeric citations
%\setcitestyle{nosort}      %% With 'acmnumeric', to disable automatic
                            %% sorting of references within a single citation;
                            %% e.g., \cite{Smith99,Carpenter05,Baker12}
                            %% rendered as [14,5,2] rather than [2,5,14].
%\setcitesyle{nocompress}   %% With 'acmnumeric', to disable automatic
                            %% compression of sequential references within a
                            %% single citation;
                            %% e.g., \cite{Baker12,Baker14,Baker16}
                            %% rendered as [2,3,4] rather than [2-4].


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format must update the
%% '\documentclass' and topmatter commands above; see
%% 'acmart-pacmpl-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption

\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.7, 0.1, 0.1}   % red
\definecolor{tacticcolor}{rgb}{0.1, 0.2, 0.6}    % blue
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green
\definecolor{attributecolor}{rgb}{0.7, 0.1, 0.1} % red

% TODO: replace \check and ̌  by \widecheck
%% code from mathabx.sty and mathabx.dcl
%% This code is here to define the \widecheck control sequence without importing mathabx
\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
      <5> <6> <7> <8> <9> <10>
      <10.95> <12> <14.4> <17.28> <20.74> <24.88>
      mathx10
      }{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathAccent{\widecheck}{0}{mathx}{"71}
\DeclareMathAccent{\wideparen}{0}{mathx}{"75}

\usepackage{listings}
\def\lstlanguagefiles{lstlean.tex}
\lstset{language=lean,breakatwhitespace,xleftmargin=0pt, basicstyle=\ttfamily\small}
\usepackage{stmaryrd}
\newcommand{\B}{\mathbb{B}}
\newcommand{\lil}{\lstinline}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ZFC}{\mathsf{ZFC}}
\newcommand{\CH}{\mathsf{CH}}

\usepackage{amsthm}
% \theoremstyle{theorem}
\newtheorem{thm}{Theorem}[section]
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\DeclareMathOperator{\cf}{cf}
\DeclareMathOperator{\Ord}{Ord}

\usepackage{tikz-cd}

\begin{document}

%% Title information
\title{A Formal Proof of the Independence of the Continuum Hypothesis}
                                        %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
% \titlenote{with title note}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
% \subtitle{Subtitle}                     %% \subtitle is optional
% \subtitlenote{with subtitle note}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Jesse Michael Han}
% \authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
% \orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  % \position{Position1}
  \department{Department of Mathematics}              %% \department is recommended
  \institution{University of Pittsburgh}            %% \institution is required
  \streetaddress{4200 Fifth Ave}
  \city{Pittsburgh}
  \state{PA}
  \postcode{15260}
  \country{USA}                    %% \country is recommended
}
\email{jessemichaelhan@gmail.com}          %% \email is recommended

%% Author with two affiliations and emails.
\author{Floris van Doorn}
% \authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{0000-0003-2899-8565}             %% \orcid is optional
\affiliation{
  % \position{Position2a}
  \department{Department of Mathematics}              %% \department is recommended
  \institution{University of Pittsburgh}            %% \institution is required
  \streetaddress{4200 Fifth Ave}
  \city{Pittsburgh}
  \state{PA}
  \postcode{15260}
  \country{USA}                    %% \country is recommended
}
\email{fpvdoorn@gmail.com}         %% \email is recommended

%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  We describe a formal proof of the independence of the continuum hypothesis (\(\mathsf{CH}\)) in the Lean theorem prover. We use Boolean-valued models to give forcing arguments for both directions, using Cohen forcing for the consistency of \(\neg \mathsf{CH}\) and a \(\sigma\)-closed forcing for the consistency of \(\mathsf{CH}\).

  % reasons for changes:

  % `Cohen forcing' means a very particular type of forcing which has a unique implementation on either the ctm or bvm side, but 'sigma-closed' is merely a combinatorial condition on a forcing poset/boolean algebra the same way that 'kappa-cc' is

  % avoid double negation e.g. 'not disprovable' by formulating in terms of consistency instead
  % i doubt anyone will be confused by this and we'll have to explain somewhere why the soundness theorem lets us use consistency results to prove unprovability results anyways

% We use Boolean-valued models and forcing to give a formal proof of the independence of the continuum hypothesis ($\mathsf{CH}$) in the Lean theorem prover. We use a forcing argument for both directions, using Cohen forcing to show that $\mathsf{CH}$ is unprovable and using $\sigma$-closed forcing to show that $\mathsf{CH}$ is not disprovable.
\end{abstract}


%TODO
%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
% \begin{CCSXML}
% <ccs2012>
% <concept>
% <concept_id>10011007.10011006.10011008</concept_id>
% <concept_desc>Software and its engineering~General programming languages</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
% <concept>
% <concept_id>10003456.10003457.10003521.10003525</concept_id>
% <concept_desc>Social and professional topics~History of programming languages</concept_desc>
% <concept_significance>300</concept_significance>
% </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Software and its engineering~General programming languages}
% \ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code

%% Keywords
%% comma separated list
\keywords{continuum hypothesis, forcing, Lean, set theory, ZFC} %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}
\label{sect:intro}
The continuum hypothesis ($\mathsf{CH}$) states that there is no cardinality between $\omega$, the smallest infinite cardinal and $\mathfrak{c}$, the cardinality of the continuum.
It was introduced by Cantor \cite{cantor1878beitrag} in 1878 and was the first problem on Hilbert's list of twenty-three outstanding problems in mathematics.
G\"odel \cite{godel1938consistency} proved in 1938 that $\mathsf{CH}$ was consistent with $\ZFC$, and later conjectured that $\mathsf{CH}$ is independent of $\ZFC$, i.e. neither provable nor disprovable from the $\ZFC$ axioms.
In 1963, Paul Cohen developed \emph{forcing} \cite{cohen-the-independence-of-the-continuum-hypothesis-1,cohen1964independence2}, which allowed him to prove the consistency of $\neg \mathsf{CH}$, and therefore complete the independence proof.
For this work, which marked the beginning of modern set theory, he was awarded a Fields medal---the only one to ever be awarded for a work in mathematical logic.

The independence of \(\CH\) has also been an open formalization problem. Since 2004, Freek Wiedijk has maintained a list (\emph{Formalizing 100 theorems}~\cite{wiedijk100theorems}) of one hundred problems for formalized mathematics, with the independence of \(\CH\) as the 24th. As of 2019, it was one of the six remaining problems.

In this paper we describe the successful completion of the Flypitch project\footnote{\url{https://flypitch.github.io}} (\textbf{F}ormal\textbf{ly} \textbf{p}roving the \textbf{i}ndependence of \textbf{t}he \textbf{c}ontinuum \textbf{h}ypothesis).
We formalize forcing with Boolean-valued models, and use Cohen forcing to construct a Boolean-valued model of \(\ZFC\) where \(\CH\) is false, and a \(\sigma\)-closed forcing to construct a Boolean-valued model of \(\ZFC\) where \(\CH\) is true. We then combine this with a deep embedding of first-order logic, including a proof system and the axioms of \(\ZFC\), to verify that \(\CH\) is neither provable nor disprovable from \(\ZFC\).

Our formalization\footnote{\url{https://github.com/flypitch/flypitch}} uses the Lean 3 theorem prover, building on top of \textsf{mathlib}~\cite{mathlib}. % TODO(after review): update reference
Lean is an interactive proof assistant under active development at Microsoft Research~\cite{de2015lean, ullrich2019counting}.
It implements the Calculus of Inductive Constructions and has a similar metatheory to Coq, adding definitional proof irrelevance, quotient types, and a noncomputable choice principle.
Our formalization makes as much use of the expressiveness of Lean's dependent type theory as possible, using constructions which are impossible or unwieldy to encode in HOL, let alone ZF.
The types of cardinals and ordinals in \textsf{mathlib}, which are defined as equivalence classes of (well-ordered) types, live one universe level higher than the types used to construct them, and our models of set theory require as input an entire universe of types. Our encoding of first-order logic also uses parameterized inductive types which ensure that type-correctness implies well-formedness, eliminating the need for separate well-formedness proofs.

% This forcing argument to show that $\mathsf{CH}$ is consistent is not the proof that G\"odel gave in 1938, who instead used the constructible universe $L$, where $\mathsf{CH}$ holds. We decided to formalize this proof so that we used an forcing argument for both parts of the independence.

The method of forcing with Boolean-valued models was developed by Solovay and Scott \cite{scott1967proof,scott-solovay} as a simplification of Cohen's method.
Some of these simplifications were incorporated by Shoenfield \cite{shoenfield1971unramified} into a general theory of forcing using partial orders, and it is in this form that forcing is usually practiced.
While both approaches have essentially the same mathematical content (see e.g.\ \cite{kunen2014set, jech2013set, moore2019method}), there are several reasons why we chose to use Boolean-valued models.
The main reason is the directness of forcing with Boolean-valued models, which bypasses the need for the L\"owenheim-Skolem theorems, Mostowski collapse, countable transitive models, or genericity considerations for filters.
The theory of forcing with Boolean-valued models also cleanly splits into several parts, allowing us formalize different components in parallel (e.g. a general theory of Boolean-valued semantics, a library for calculations in complete Boolean algebras, a construction of Boolean-valued models of set-theory) and later recombine them. In particular, our library for Boolean-valued semantics for first-order logic is completely general and can be reused for other formalization projects. Finally, our Boolean-valued models of set theory are inductive types generalizing the Aczel encoding of set theory into dependent type theory; consequently, the automatically-generated induction principle \emph{is} \(\in\)-induction, leading to cleaner proofs.
% Some of these components include: a general theory of Boolean-valued semantics for first-order logic, a library for calculations inside complete Boolean algebras, and a construction of Boolean-valued models of set theory.

% We made sure that the individual components of this formalization are reusable for other projects, e.g.\ to formalize the Boolean-valued semantics of stochastic $\lambda$-calculus~\cite{scott2014stochastic, bacci2018boolean}.

% Finally, we observed that our construction of Boolean-valued models of set theory (\Cref{sect:bset}) is amenable to structural induction. As with Coq, Lean is able to encode extremely complex objects and reason about their specifications using inductive types.
% However, the user must be careful to choose the encoding so that properties they wish to reason about are accessible by structural induction, which is the most natural mode of reasoning in the proof assistant.
% After observing (1) that the Aczel encoding of $\ZFC$ as an inductive type is essentially a special case of the recursive \emph{name} construction from forcing (\Cref{sect:bset}),
% and (2) that the automatically-generated induction principle for that inductive type \emph{is} $\in$-induction,
% it is easy to see that this encoding can be modified to produce a Boolean-valued model of set theory where, again, $\in$-induction comes for free.

% TODO: maybe this is better in the main text. We can mention it briefly here.

% \textbf{Amenability to structural induction.}
% As with Coq, Lean is able to encode extremely complex objects and reason about their specifications using inductive types.
% However, the user must be careful to choose the encoding so that properties they wish to reason about are accessible by structural induction, which is the most natural mode of reasoning in the proof assistant.
% After observing (1) that the Aczel-Werner encoding of $\ZFC$ as an inductive type is essentially a special case of the recursive \emph{name} construction from forcing (c.f. \ref{sect:boolean-semantics}),
% and (2) that the automatically-generated induction principle for that inductive type \emph{is} $\in$-induction,
% it is easy to see that this encoding can be modified to produce a Boolean-valued model of set theory where, again, $\in$-induction comes for free.

\subsection{Proof Outline}
\label{subsect:intro:outline}
$\ZFC$ is a collection of first-order sentences in the language of set theory. For convenience, we conservatively extend this language with five function symbols (see \Cref{subsect:fol:zfc}) which make it easier to formulate $\CH$. Our goal is to show that we cannot construct proofs\footnote{By proof we mean a natural deduction tree (see \Cref{subsect:fol:terms}).} of either $\CH$ or $\neg\CH$ from $\ZFC$.

The usual method to show that a statement is unprovable is to construct a model where the statement is false, and apply the soundness theorem; our method is similar, except that we use Boolean-valued semantics and a Boolean-valued soundness theorem (see \Cref{sect:boolean-semantics}).
The difference between Boolean-valued models and ordinary models is that the truth values in a Boolean-valued model \lil{M} live in a complete Boolean algebra \lil{(𝔹, ⊓, ⊔, ⨅, ⨆,⊥,⊤)}.
This means that, e.g.\ equality is interpreted as a function \lil{eq : M → M → 𝔹} satisfying \lil{𝔹}-valued reflexivity, symmetry, and transitivity (for example, transitivity is formulated as \lil{∀ x y z, eq(x, y) ⊓ eq(y, z) ≤ eq(x, z)}).
All interpretations of function symbols and relation symbols in \lil{M} must satisfy \lil{𝔹}-valued congruence lemmas with respect to equality.
If we can construct two Boolean-valued models of $\ZFC$, one where $\CH$ holds, and one where $\CH$ fails, then by the Boolean-valued soundness theorem, $\CH$ is independent from $\ZFC$.

For any complete Boolean algebra $\mathbb{B}$ we implement the set-theoretic universe \(V^{\mathbb{B}}\) of \(\mathbb{B}\)-valued sets by generalizing the Aczel encoding of set theory (called \lil{pSet}, see \Cref{sect:bset}), obtaining a type \lil{bSet 𝔹} of $\mathbb{B}$-valued sets. The fundamental theorem of forcing for Boolean-valued models \cite{hamkins2012well}, translated to our situation, then states that \lil{bSet 𝔹} is a \lil{𝔹}-valued model is \(\ZFC\).
% An element of \lil{x : bSet 𝔹} has three components:
% \begin{itemize}
% \item An indexing type \lil{α : Type};
% \item A function \lil{A : α → bSet 𝔹} pointing to the (possible) elements of \lil{x};
% \item A \lil{𝔹}-valued predicate \lil{B : α → 𝔹} which expresses that \lil{A a ∈ x} has truth value (at least) \lil{B a}.
% \end{itemize}
% The fundamental theorem of forcing \cite{hamkins2012well} states that \lil{bSet 𝔹} forms a Boolean-valued model of $\ZFC$.
% \lil{bSet 𝔹} is a generalization of the Aczel encoding of set theory \cite{aczel1978type}, which is called \lil{pSet} in Lean.
% % In this encoding, the third component is missing.
% We can also interpret \lil{pSet} as \lil{bSet unit}, where \lil{unit} is the trivial Boolean algebra (with $\top=\bot$).

% The properties of \lil{bSet 𝔹} can vary wildly depending on the choice of the complete Boolean algebra \lil{𝔹}. There is always a map \lil{check : pSet → bSet 𝔹}, $x \mapsto \widecheck{x}$; in general, $\widecheck{x}$ might have different properties than $x$, but \(\Delta_0\) properties (i.e. definable with only bounded quantification) are always preserved (for example, \lil{bSet 𝔹} thinks $\widecheck{\omega}$ is $\omega$).
To show the independence of \(\CH\), it remains to construct two appropriate complete Boolean algebras \lil{𝔹} such that in \lil{bSet 𝔹}, the formula $\CH$ is true ($\top$) in one model and $\CH$ is false ($\bot$) in the other. The properties of \lil{bSet 𝔹} can vary wildly depending on the choice of the complete Boolean algebra \lil{𝔹}. There is always a map \lil{check : pSet → bSet 𝔹}, $x \mapsto \widecheck{x}$, but in general, $\widecheck{x}$ might have different properties than $x$. Making a good choice of \(\B\) and controlling the behavior of the check-names is precisely the task of forcing (\Cref{sect:forcing}).

% To force the negation of the continuum hypothesis, we define Cantor space $2^{\aleph_2 \times \mathbb{N}}$ with its usual product topology (see TODO).
% Then let $\B_{\mathsf{cohen}}$ be the regular open algebra of the Cantor space (a set $O$ is a regular open if $O$ is equal to the interior of the closure of $O$).
% Now $\B$ is a complete Boolean algebra, so \lil{bSet 𝔹} models $\ZFC$.
% Internally to this model we can construct an injection $\widetilde{\chi} : \aleph_2 \to \mathcal{P}(\omega)$, in the following way.
% For each $\nu \in \aleph_2$, we associate the $\B$-valued characteristic function $\chi_\nu : \mathbb{N} \to \B$ by $n \mapsto \{f \mid f(\nu, n) = 1\}$.
% This induces an subset $\widetilde{\chi_{\nu}} \subseteq \mathbb{N}$ internal to \lil{bSet 𝔹}, which is called a \emph{Cohen real}.
% This way we obtain an function \(\widecheck{\aleph_2} \to \mathcal{P}(\mathbb{N})\) internal to \lil{bSet 𝔹}.
% We can now show that \lil{bSet 𝔹} thinks this function is injective, and we finish by showing that \lil{bSet 𝔹} thinks that \(\widecheck{\aleph_2}\) is $\aleph_2$ to show that $\neg\CH$ holds in \lil{bSet 𝔹}.
% The proof that \lil{bSet 𝔹} preserves cardinal numbers is really the technical heart of the matter, and relies on a combinatorial property of $\B$ called the \emph{countable chain condition} (CCC).
% The proof that $\B$ has the CCC requires a detailed combinatorial analysis of the basis of the product topology for $2^{\aleph_2 \times \mathbb{N}}$.
% We handle this with a general result in transfinite combinatorics called the \emph{$\Delta$-system lemma}.
% % we can omit the last two sentences, if needed

% For the other direction, to force the continuum hypothesis, we define the collapse poset to be the poset of countable partial functions
% \(\mathbb{P}_{\mathsf{collapse}} := \aleph_1 \rightharpoonup \mathcal{P}(\omega)\), and topologize $\mathcal{P}(\omega)^{\aleph_1}$ with the basis of opens
% \[\left\{ D_p := \{g : \aleph_1 \to \mathcal{P}(\omega) \mid g \text{ extends } p\} \right\}_{p \in \mathbb{P}_{\mathsf{collapse}}}\]

% The collapse algebra $\mathbb{B}_{\mathsf{collapse}}$ is now defined to be the regular opens in this topology.
% In the resulting model \lil{bSet 𝔹} we can construct a surjection \(F : \aleph_1 \twoheadrightarrow \mathcal{P}(\omega)\). (TODO) (see TODO)
% This depends on \(\sigma\)-closedness (TODO).

Traditional presentations of forcing, even with Boolean-valued models (e.g. \cite{bell2011set}, \cite{jech2013set}), are careful to stay within the foundations of $\ZFC$, emphasizing that all arguments may be performed internal to a model of $\ZFC$, etc. In order to formalize these set-theoretic arguments in a type-theoretic metatheory, it is important to separate their mathematical content from their metamathematical content. It is not immediately clear what parts of these arguments use their set-theoretic foundation in an essential way and require modification in the passage to type theory. Our formalization clarifies some of these questions.

We use custom domain-specific tactics and various forms of automation throughout our formalization, notably a tactic library for simulating natural deduction proofs inside a complete Boolean algebra \Cref{sect:metaprogramming}).
This reveals another advantage of working in a proof assistant: the bookkeeping of Boolean truth-values, sometimes regarded as a tedious aspect of the Boolean-valued approach to forcing, can be automated away.

\paragraph{Contributions}
An earlier paper \cite{DBLP:conf/itp/HanD19} describes a formalization of Cohen forcing and the unprovability of \(\CH\). In order to keep our presentation self-contained, % , some of the material discussed in \cite{DBLP:conf/itp/HanD19}
% is reproduced here.
we reproduce some of that material here.
Our main contribution is a formalization of collapse forcing and the unprovability of \(\neg \CH\), thereby providing the first formalization of the independence of \(\CH\) in a single theorem prover. For reasons we will see in \Cref{sect:forcing}, the forcing argument for \(\CH\) requires far more set theory and is harder to formalize than the forcing argument for \(\neg \CH\). Moreover, we also elaborate on parts of the formalization which were omitted from \cite{DBLP:conf/itp/HanD19}. We unify and streamline the presentation of both forcing arguments in \Cref{sect:forcing}% , and include an extensive discussion of our forcing argument for \(\CH\) in \Cref{subsect:collapse},
and expand our discussion of the formalization of the \(\Delta\)-system lemma \Cref{lemma:delta-system-lemma:general}.
% TODO: maybe uncomment this last sentence after the paper is finalized

\paragraph{Sources}
Our strategy for forcing \(\neg \CH\) is a synthesis of the proofs in the textbooks of Bell (\cite{bell2011set}, Chapter 2) and Manin (\cite{manin2009course}, Chapter 8).
For the $\Delta$-system lemma, which we use to verify that Cohen forcing is CCC, we follow Kunen (\cite{kunen2014set}, Chapters 1 and 5).

We were unable to find a reference for a purely Boolean-valued account of forcing \(\CH\). We loosely followed the conventional arguments given by Weaver (\cite{weaver2014forcing}, Chapter 12) and Moore (\cite{moore2019method}), and base our construction of \(\mathbb{B}_{\mathsf{collapse}}\) on the collapse algebras defined by Bell (\cite{bell2011set}, Exercise 2.18).

\paragraph{Related work} Set theory and first-order logic are both common targets for formalization. Shankar \cite{shankar1997metamathematics} used a deep embedding of first-order logic to formalize incompleteness theorems. Harrison gives a deeply-embedded implementation of first-order logic in HOL Light \cite{harrison1998formalizing} and a proof-search style account of the completeness theorem in \cite{harrison2009handbook}. Other formalizations of first-order logic can be found in Isabelle/HOL (\cite{Ridge2005AMV}, \cite{schlichtkrull2018formalization},\cite{FOL-Fitting-AFP}) and Coq (\cite{ilik2010constructive}, \cite{DBLP:conf/tphol/OConnor05}).

A large body of formalized set theory has been completed in Isabelle/ZF, led by Paulson and his collaborators \cite{paulson1996mechanizing, paulson1993set, paulson2002reflection}, including the relative consistency of \(\mathsf{AC}\) with $\mathsf{ZF}$ \cite{paulson2008relative}. Building on this, Gunther, Pagano, and Terraf have taken some first steps towards formalizing forcing \cite{gunther2018first, gunther2019mechanization}, by way of generic extensions of countable transitive models.

% Our tactic library for Boolean-valued logic (\Cref{sect:metaprogramming}) is inspired by work of Hudon \cite{Hudon2015TheUM} on Unit-B, who used similar methods to embed a proof system for temporal logic \cite{unitb}.
% See also the Related Work (\Cref{sect:related-work}).

% \subparagraph*{Viewing the formalization}
% The code blocks in this paper were taken directly from our formalization, but for the sake of readability, we sometimes omit or modify universe levels, type ascriptions, and casts. We refer the interested reader to our repository (see Supplemental Material on page 1) which contains a guide on compiling and navigating the source files of the project.

\section{First-order logic}
\label{sect:fol}

The starting point for first-order logic is a \emph{language} of relation and function symbols.
We represent a language as a pair of $\N$-indexed families of types, each of which is to be thought of as the collection of relation (resp. function) symbols stratified by arity:
\begin{lstlisting}
structure Language : Type (u+1) :=
(functions : ℕ → Type u)
(relations : ℕ → Type u)
\end{lstlisting}
\subsection{Terms, Formulas and Proofs}
\label{subsect:fol:terms}
The main novelty of our implementation of first-order logic is the use of \emph{partially applied} terms and formulas, encoded in a parameterized inductive type where the $\N$ parameter measures the difference between the arity and the number of applications.
The benefit of this is that it is impossible to produce an ill-formed term or formula, because type-correctness is equivalent to well-formedness.
This eliminates the need for separate well-formedness proofs.

Fix a language $L$. We define the type of \textbf{preterms} as follows:
\begin{lstlisting}
inductive preterm (L : Language.{u}) :
    ℕ → Type u
| var : ℕ → preterm 0 -- notation `&`
| func {l : ℕ} : L.functions l → preterm l
| app {l : ℕ} :
    preterm (l + 1) → preterm 0 → preterm l
\end{lstlisting}
A member of \lil{preterm n} is a partially applied term.
If applied to \lil{n} terms, it becomes a term.
We define the type of well-formed terms \lil{term L} to be \lil{preterm L 0}.

% % cut?
% There are other methods to define well-typed terms, for example using a nested inductive type with a constructor (replacing the second and third constructor in our definition)
% \begin{lstlisting}
% | app : ∀ {l : ℕ}, L.functions l →
%     vector term l → term
% \end{lstlisting}
% Here \lil{vector term l} is a $l$-tuple of terms.
% Lean has limited support for nested inductive types, but defining definitions by recursion on a nested inductive type is inconvenient.

The type of \textbf{preformulas} is defined similarly:
\begin{lstlisting}
inductive preformula (L : Language.{u}) :
    ℕ → Type u
| falsum : preformula 0 -- notation ⊥
| equal : term L → term L → preformula 0
    -- notation ≃
| rel {l : ℕ}, L.relations l → preformula l
| apprel {l : ℕ}, preformula (l + 1) →
    term L → preformula l
| imp : preformula 0 → preformula 0 →
    preformula 0 -- notation ⟹
| all : preformula 0 → preformula 0
    -- notation ∀'
\end{lstlisting}
We choose this definition of \lil{preformula} to mimic \lil{preterm}.
A member of \lil{preformula n} is a partially applied formula, and if applied to \lil{n} terms, it becomes a formula.
The type of well-formed formulas \lil{formula L} is defined to be \lil{preterm L 0}.
Implication is the only primitive binary connective and universal quantification is the only primitive quantifier. Since we use classical logic, we can define the other connectives and quantifiers from these.
% In particular, we define negation \lil{∼ f} to be \lil{f ⟹ ⊥} and existential quantification \lil{∃' f} to be \lil{∼ ∀' ∼ f}.
Note that implication and the universal quantifier cannot be applied to preformulas that are not fully applied.
% We could also define an inductive type where the constructors \lil{rel} and \lil{apprel} were replaced by the single constructor % cut? this paragraph
% \begin{lstlisting}
% | rel {l : ℕ} : L.relations l →
%     vector term l → formula
% \end{lstlisting}
% This would not even result in a nested inductive type.
% However, we found it more convenient to adapt operations and proofs from \lil{preterm} to \lil{preformula} using our definition.
% Using vectors results in some extra proof steps for reasoning about vectors.
% Our approach also results in some extra proof steps, but they are the same as the steps in the corresponding proofs for preterms.

It is also possible to define well-typed terms and formulas using vectors of terms and nested inductive types. However, we avoided these kinds of definitions because Lean has limited support for nested inductive types. In the case of formulas, this would not even result in a nested inductive type, but we found it more convenient to adapt operations and proofs from \lil{preterm} to \lil{preformula} using our definition.

We use de Bruijn indices to avoid variable shadowing. This means that the variable \lil{&m} under \lil{k} is bound if $m<k$ and otherwise represents the $(m-k)$-th free variable.
We define the usual operations of lifting and substitution for terms and formulas, needed when using de Bruijn variables.
We use the notation \lil{t ↑' n # m} to mean the preterm of preformula \lil{t} where all variables which are at least \lil{m} are increased by \lil{n}.
The lift \lil{t ↑' n # 0} is abbreviated to \lil{t ↑ n}.
The substitution \lil{t[s // n]} is defined to be the term or formula \lil{t} where all variables that represent the \lil{n}-th free variable are replaced by \lil{s}.
More specifically, if an occurrence of a variable \lil{&(n+k)} is under \lil{k} quantifiers, then it is replaced by \lil{s ↑ (n+k)}.
Variables \lil{&m} for $m>n+k$ are replaced by \lil{&(m-1)}.

Our proof system is a natural deduction calculus, and all rules are motivated to work well with backwards-reasoning. The type of proof trees is given by the following inductive family of types:
\label{def:prf}
\begin{lstlisting}
inductive prf :
    set (formula L) → formula L → Type u
| axm Γ A : A ∈ Γ → prf Γ A
| impI Γ A B : prf (insert A Γ) B →
    prf Γ (A ⟹ B)
| impE Γ A B : prf Γ (A ⟹ B) → prf Γ A →
    prf Γ B
| falsumE Γ A : prf (insert ∼A Γ) ⊥ → prf Γ A
| allI Γ A : prf ((λ f, f ↑ 1) '' Γ) A →
    prf Γ (∀' A)
| allE₂ Γ A t : prf Γ (∀' A) →
    prf Γ (A[t // 0])
| ref Γ t : prf Γ (t ≃ t)
| subst₂ Γ s t f : prf Γ (s ≃ t) →
    prf Γ (f[s // 0]) → prf Γ (f[t // 0])
\end{lstlisting}
In \lil{allI} the notation \lil{(λ f, f ↑ 1) '' Γ} means lifting all free variables in \lil{Γ} by one.
A term of type \lil{prf Γ A}, denoted \lil{Γ ⊢ A}, is a proof tree encoding a derivation of $A$ from $\Gamma$.
We also define provability as the proposition stating that a proof tree exists.
\begin{lstlisting}
def provable (Γ : set (formula L))
  (f : formula L) : Prop := nonempty (prf Γ f)
\end{lstlisting}
Our current formalization does not use the data of proof trees in an essential way, but we defined them so that we can define manipulations on proof trees (like detour elimination) in future projects.
% maybe restore?
% We prove various meta-theoretic properties about provability, like weakening and the substitution theorem.
% \begin{lstlisting}
% def weakening : Γ ⊆ Δ → Γ ⊢ A → Δ ⊢ A
% def substitution : Γ ⊢ A →
%     (λ f, f[s // n]) '' Γ ⊢ A[s // n]
% \end{lstlisting}
Besides Boolean-valued semantics (\Cref{sect:boolean-semantics}), we also formalize ordinary first-order semantics, and our work includes a formalization of the completeness (and compactness) theorems using Henkin term models.

\subsection{ZFC}
\label{subsect:fol:zfc}

Usually, the language of set theory has one binary relation symbol and no function symbols.
To make the language easier to work with, and to concisely formulate the continuum hypothesis, we conservatively extend \(\ZFC\) with the following function symbols: the empty set \(\varnothing\), ordered pairing \(({-},{-})\), the natural numbers \(\omega\), power set \(\mathcal{P}({-})\) and union \(\bigcup({-})\).
This gives a conservative extension of the regular theory of ZFC, because these function symbols are all definable.
% As part of our future work, we want to formalize these facts, so that we actually prove the independence of the continuum hypothesis in a language with only one non-logical symbol. % move to future work

What we call \(\ZFC\) comprises the axioms of extensionality and regularity, Zorn's lemma, the strong axiom of collection, and axioms characterizing the new symbols (\(\varnothing\), \((-,-)\), \(\omega\), \(\mathcal{P}(-)\), \(\bigcup(-)\)). We will explain some of these axioms in more detail here.

We don't uniquely characterize ordered pairs, but specify the equality on ordered pairs:
\[\forall x\ y\ z\ w, (x,y)=(z,w) \leftrightarrow x = z \wedge y = w.\]
We don't have the usual axiom of pairing, but this axiom is derivable from the other axioms.
Our version of the axiom of infinity states that $\omega$ is the least limit ordinal.
Our version of Zorn's lemma is states that any non-empty collection of sets closed under unions of $\in$-chains has a maximal element.
Finally, the axiom schema of collection we use states that for every formula \(\varphi(x,y,\vec p)\) we have the axiom stating that if \(\varphi(x,y,\vec p)\) is a total relation with parameters \(\vec p\), then its image is a set:
\begin{gather*}
\forall \vec p\; A, (\forall x \in A, \exists y, \varphi(x,y,p)) \Rightarrow \exists B, \\
(\forall x \in A, \exists y \in B, \varphi(x,y,p)) \wedge
(\forall y \in B, \exists x \in A, \varphi(x,y,p)).
\end{gather*}

Our formulation of \(\CH\) states that there is no ordinal between \(\omega\) and \(\mathcal{P}(\omega)\). It is defined to be the sentence
\[\CH:=\forall x, \Ord(x) \Rightarrow x \le \omega \vee \mathcal{P}(\omega) \le x,\]
where \(\Ord(x)\) means ``\(x\) is an ordinal'' and \(x \le y\) means that there is a surjection from a subset of \(y\) to \(x\). In code, we have:
\begin{lstlisting}
def CH_formula : formula L_ZFC :=
∀' (is_ordinal ⟹
  leq_f[omega_t//1] ⊔ leq_f[Powerset_t omega_t//0])
\end{lstlisting}
The substitution ensures that the inequality \lil{leq_f} is applied to the correct arguments, and \lil{⊔} is notation for disjunction.

\section{Boolean-valued semantics}
\label{sect:boolean-semantics}
A \textbf{complete Boolean algebra} is a Boolean algebra $\B$ with additional operations infimum $(\bigsqcap)$ and supremum $(\bigsqcup)$ of any subset of $\B$.
We use $\sqcap, \sqcup, \implies, \top$, and $\bot$ to denote meet, join, material implication, top, and bottom. For more details on complete Boolean algebras, we refer the reader to the textbook of Halmos-Givant~\cite{givant2008introduction}.

\begin{defn}\label{def:boolean-valued-structure}
  Fix a language $L$ and a complete Boolean algebra $\B$. A \textbf{$\B$-valued structure} (or \lil{bStructure L 𝔹}) is a type $M$ equipped with the following.
  \begin{itemize}
    \item for every $n$-ary function symbol in a map $M^n \to M$;
    \item for every $n$-ary relation symbol a map $M^n \to \B$;
    \item a function ${\approx}:M\to M\to\B$ that is a Boolean valued congruence relation. This means that e.g.\
    $x\approx y\sqcap y\approx z\le x\approx z$ and that \[\bigsqcap_i x_i\approx y_i \le f(\vec x)\approx f(\vec y).\]
    There are similar conditions for reflexivity, symmetry and congruence for relation symbols.
  \end{itemize}
\end{defn}

Given a preterm \lil{t} in the language, we can realize it in any $\B$-valued structure $M$.
For this, we need to know the free variables in \lil{t}.
To do this conveniently with de Bruijn variables, we say that a (pre)term \lil{t} is \emph{bounded by \lil{l}} if all free variables are less than \lil{l} (i.e. all variables under \lil{k} quantifiers are less than \lil{k+l}).
Given \lil{t : preterm n} which is bounded by \lil{l}, and a realization \lil{v : vector M l} of the free variables, we define the realization $\llbracket t \rrbracket_M^v : M^n \to M$ by structural recursion on $t$.

For a formula $\varphi$ we do the same: we define bounded (pre)formulas, and define an realization $\llbracket \varphi \rrbracket_M^v : M^n \to \B$ by structural recursion.
If $\varphi$ is a sentence, the realization in a structure is just a element of the Boolean algebra: $\llbracket \varphi \rrbracket_M : \B$.

Since the truth values in a Boolean-valued model live inside the Boolean algebra $\B$ instead of just being true or false, we have to take a little care when stating the soundness theorem for Boolean-valued models.
Usually, a soundness theorem states something like ``if $\varphi$ is provable from hypotheses in $\Gamma$ then in every model where $\Gamma$ holds, $\varphi$ also holds.''
With Boolean truth-values, this is instead stated as an inequality of truth values. % This motivates the following definition
\begin{defn}
We say that a set of sentences $\Gamma$ \emph{forces a sentence} $\varphi$, written $\Gamma \models_{\B}\varphi$, if for all non-empty $\B$-valued structures $M$ we have $\big(\bigsqcap_{\psi\in\Gamma}\big \llbracket \psi \rrbracket_M)\le\llbracket \varphi \rrbracket_M$.
\end{defn}
Using this definition, we can now state the Boolean-valued soundness theorem: \label{boolean-soundness}
\begin{lstlisting}
theorem boolean_soundness {Γ : set (sentence L)}
    {ϕ : sentence L} : Γ ⊢ ϕ → Γ ⊨[𝔹] ϕ
\end{lstlisting}
The proof is a straightforward structural induction.

\section{Boolean-valued models of set theory}
\label{sect:bset}
\subsection{The Aczel encoding}
\label{subsect:bset:aczel}
Our starting point is the Aczel encoding of \(\ZFC\) (\cite{aczel1978type, aczel1986type, aczel1982type}) into dependent type theory.
This was implemented in Coq by Werner \cite{werner1997sets}, and in Lean's \textsf{mathlib} by Carneiro \cite{mario1}.
The idea is to take a type universe \lstinline{Type u} and imitate the cumulative hierarchy construction with an inductive type:
\begin{lstlisting}
inductive pSet : Type (u+1)
| mk (α : Type u) (A : α → pSet) : pSet
\end{lstlisting}
For an element \lil{x = ⟨α, A⟩ : pSet}, the function \lil{A} points to the elements of \lil{x}.
We can define the empty set as \lstinline{∅ := ⟨empty, empty.elim⟩ : pSet}.
Note that \lil{pSet} does not satisfy the axiom of extensionality.
In order to obtain a model where the axiom of extensionality holds, we must quotient \lstinline{pSet} by \emph{extensional equivalence}, which is defined by structural recursion: %  {≈}% .
% % We have to be a bit careful with defining extensional equivalence.
% % Although extensional equivalence and membership are easily defined in terms of each other,
% % one has to be careful to make sure the definition is well-founded.
% \begin{lstlisting}
% x ≈ y ↔ ∀w, w ∈ x ↔ w ∈ y
% x ∈ ⟨α, A⟩ ↔ ∃a, x ≈ A a
% \end{lstlisting}
% In order to make this well-founded, equivalence is defined by structural recursion:
\begin{lstlisting}
def equiv : pSet → pSet → Prop
| ⟨α,A⟩ ⟨β,B⟩ := (∀a, ∃b, equiv (A a) (B b)) ∧
  (∀b, ∃a, equiv (A a) (B b))
\end{lstlisting}
One can then define membership from equivalence and check that modulo extensional equivalence, \lstinline{pSet} is a model of \(\ZFC\).

% \paragraph{Two roads to \lstinline{bSet}}
% We describe two ways by which one can start at the ordinary model of \(\ZFC\) \lstinline{pSet} and end with a Boolean-valued model \lstinline{bSet}.

% First, note that we can construct a model of \(\ZFC\) roughly equivalent to \lstinline{pSet} as follows:
% \begin{lstlisting}
% inductive bSet : Type (u+1)
% | mk (α : Type u) (A : α → bSet)
%   (B : α → bool): bSet
% \end{lstlisting}
% At first glance, \lstinline{bSet} adds large amounts of unnecessary information---while with \lstinline{pSet}, anything pointed to by an indexing function \lstinline{A} is a member of a set, \lstinline{bSet} only counts what is also assigned \lstinline{tt : bool}---and we can reconstruct \lstinline{pSet} from \lstinline{bSet} by recursively discarding anything which is assigned \lstinline{ff : bool} anyways. However, if we remember that \lstinline{bool} is a complete Boolean algebra \lstinline{⟨bool, ⊤, ⊥, ⊓, ⊔, ⨅,⨆, ⟹⟩}, then an upshot of the definition of \lstinline{bSet} is that we can replace the obvious analogue of \lstinline{equiv}
% \begin{lstlisting}
% def equiv : ∀ (x y : bSet), Prop
% | ⟨α,A,A'⟩ ⟨β,B,B'⟩ := (∀ a : α, A' a = tt → ∃ b : β, B' b = tt ∧ equiv₁ (A a) (B b)) ∧ (∀b : β, B' b = tt → ∃ a : α, A' a = tt ∧ equiv₁ (A a) (B b))
% \end{lstlisting}
% with a version which avoids propositional operations and only uses the operations of a complete Boolean algebra:\footnote{Assuming \lstinline{Prop ≃ bool}, which is provable using classical logic in Lean.}
% \begin{lstlisting}
% def equiv₂ : ∀ (x y : bSet), bool
% | ⟨α,A,A'⟩ ⟨β,B,B'⟩ := ⨅ a : α, A' a ⟹ ⨆ b : β, B' b ⊓ equiv₂ (A a) (B b) ⊓  ⨅ b : β, B' b ⟹ ⨆ a : α, A' a ⊓ equiv₂ (A a) (B b)
% \end{lstlisting}
% Since this definition only interfaces with the typeclass of complete Boolean algebras, we can replace \lstinline{bool} by an arbitrary complete Boolean algebra \lstinline{𝔹} throughout, yielding: % note(jesse, October 03 2019, 05:06 PM): maybe should emphasize definition of membership instead of equality to make it clear that these things are Boolean-valued models of ZFC
% \begin{lstlisting}
% inductive bSet (𝔹 : Type u) [complete_boolean_algebra 𝔹]: Type (u+1)
% | mk (α : Type u) (A : α → bSet)
%   (B : α → 𝔹): bSet
% \end{lstlisting}
% which we later verify is a \(\mathbb{B}\)-valued model of \(\ZFC\).

\subsection{Boolean-valued sets}
\label{subsect:bset:bset}

We now want to generalize \lil{pSet} to a Boolean-valued model of \(\ZFC\). We must give a
\(\B\)-valued predicate interpreting the membership symbol \lil{∈}. We will encode this information by extending each \lil{⟨α,A⟩ : pSet} with an additional function \lil{B : α → 𝔹}, which has the effect of attaching a \emph{Boolean truth-value} to every element of \lil{⟨α,A⟩}:
\begin{lstlisting}
inductive bSet (𝔹 : Type u)
    [complete_boolean_algebra 𝔹] : Type (u+1)
| mk (α : Type u) (A : α → bSet)
    (B : α → 𝔹) : bSet
\end{lstlisting}
The \lil{𝔹}-valued predicate \lil{B} expresses that \lil{A a ∈ ⟨α, A, B⟩} has truth value (at least) \lil{B i}. For convenience, if \lstinline{x : bSet 𝔹} and \lstinline{x := ⟨α, A, B⟩}, we put \lstinline{x.type := α, x.func := A, x.bval := B}.

One can also be led to this construction by considering the recursive \emph{name}-construction from forcing, a key ingredient to building forcing extensions. Let \(\mathbb{P}\) be a poset. From e.g. (Kunen \cite{kunen2014set}, Definition IV.2.5):
\begin{defn}
  A set \(\tau\) is a \(\mathbb{P}\)-name iff \(\tau\) is a relation and for all \(\langle  \sigma, p\rangle \in \tau\) we have that \(\sigma\) is a \(\mathbb{P}\)-name and \(p \in \mathbb{P}\).
\end{defn}

In particular, if \(\mathbb{P}\) is the singleton poset, then a \(\mathbb{P}\)-name is merely a set of \(\mathbb{P}\)-names, in the same way that a term of type \lstinline{pSet} is a type-indexed collection of terms of type \lstinline{pSet}.
Reversing this observation, we can replace \(\mathbb{P}\) with a complete Boolean algebra \(\mathbb{B}\) and generalize the definition of \lstinline{pSet.mk} with a third field, so that as in the case of \(\mathbb{P}\)-names, every element of a set is assigned an element (a ``Boolean truth-value'') of \(\mathbb{B}\), again giving us \lil{bSet 𝔹}. Thus, \lil{bSet 𝔹} should be thought of as the type of \lil{𝔹}-names.

% \begin{lstlisting}
% inductive bSet {𝔹 : Type u) : Type (u+1)
% | mk (α: Type u) (A: α → bSet) (B: α → 𝔹) : bSet
% \end{lstlisting}
% Whatever is important in \lstinline{bvm}, \lstinline{bvm_extras}, \lstinline{bvm_extras2} for this argument.

\paragraph{Boolean-valued equality and membership}
We can define Boolean-valued equality and membership analogously to the definitions in \lil{pSet}.
To do this, we translate quantifiers and connectives into operations on $\B$:
\begin{lstlisting}
def bv_eq : bSet 𝔹 → bSet 𝔹 → 𝔹
| ⟨α, A, B⟩ ⟨α', A', B'⟩ :=
  (⨅a, B a ⟹ ⨆a', B' a' ⊓ bv_eq (A a) (A' a')) ⊓
  (⨅a', B' a' ⟹ ⨆a, B a ⊓ bv_eq (A a) (A' a'))
\end{lstlisting}
We abbreviate \lil{bv_eq} with the infix operator \lil{=ᴮ}.
It is now easy to define $\B$-valued membership, which we denote by \lil{∈ᴮ}.
\begin{lstlisting}
def mem : bSet 𝔹 → bSet 𝔹 → 𝔹
| x ⟨α, A, B⟩ := ⨆a, B a ⊓ x =ᴮ A a
\end{lstlisting}
While standard treatments of Boolean-valued models of \(\ZFC\) mutually define equivalence and membership so that the axiom of extensionality follows definitionally (\cite{bell2011set}, \cite{hamkins2012well}), the induction principle given by the non-mutual definition is easier to work with in our formalization.

\subsection{The fundamental theorem of forcing}
\label{subsect:bset:fundamental-thm}
The fundamental theorem of forcing for Boolean-valued models~\cite{hamkins2012well} states that for any complete Boolean algebra \lil{𝔹}, the type \lil{bSet 𝔹} forms a Boolean-valued model of $\ZFC$.

% Bell~\cite{bell2011set} gives an extremely detailed account of the verification of the $\ZFC$ axioms,
% and we faithfully followed his presentation for this part of the formalization.

We mostly follow Bell~\cite{bell2011set} for the verification of the \(\ZFC\) axioms in \lil{bSet 𝔹}.
Although most of the argument is routine, we describe some aspects of \lil{bSet 𝔹} which are revealed by this verification.

Notably, we can define subsets of a set \lil{x : bSet 𝔹} by just modifying \lil{x.bval}.
This gives a nice definition of powerset:
\begin{defn} \label{def:powerset}
  Fix a $\B$-valued set \lil{x = ⟨α, A, b⟩} and \lil{χ : α → 𝔹} be a function.
  We define the $\B$-valued set $\widetilde{\chi}$ as \lil{⟨α, A, χ⟩}.
  The \textbf{powerset} $\mathcal{P}(x)$ of $x$ is defined to be the \lil{𝔹}-valued set
  \[\text{ \lstinline{set_of_indicator χ :=} }\langle \alpha \to \B, (\lambda\; \chi, \widetilde{\chi}),\ (\lambda\;\chi, \widetilde{\chi} \subseteq^B x)\rangle.\]
\end{defn}

In particular, this gives an easy implemention of the axiom of comprehension (not just for interpretations of formulas, but for any \(\mathbb{B}\)-valued predicate on \lil{bSet 𝔹} satisfying an appropriate \(\mathbb{B}\)-valued congruence lemma): \label{def:comprehension} % TODO(jesse, October 21 2019, 02:20 PM): while cutting, maybe omit everything except variables and bSet_axiom_of_comprehension
\begin{lstlisting}
def subset.mk {u} (χ : u.type → 𝔹) : bSet 𝔹 :=
set_of_indicator (λ i, χ i ⊓ (u.bval i))

variables (ϕ : bSet 𝔹 → 𝔹) (x : bSet 𝔹)
  (H_congr : B_ext ϕ)

def comprehend : bSet 𝔹 :=
subset.mk (λ i : x.type, ϕ (x.func i))

lemma mem_comprehend_iff : ∀ {z} {Γ},
  Γ ≤ z ∈ᴮ comprehend ϕ x ↔
  Γ ≤ ⨆ (i : x.type), x.bval i ⊓ (z =ᴮ (x.func i) ⊓ (λ i : x.type, ϕ (x.func i)) i)

lemma bSet_axiom_of_comprehension {Γ : 𝔹} : Γ ≤ ⨆ y, y ⊆ᴮ x ⊓ ⨅ z, z ∈ᴮ y ⇔ (z ∈ᴮ x ⊓ ϕ z)
\end{lstlisting}
Following Bell, we verify Zorn's lemma in \lil{bSet 𝔹}.
As is the case with \lil{pSet}, establishing Zorn's lemma requires the use of a choice principle from the metatheory.
This was the most involved part of our verification of the fundamental theorem of forcing, and relies on the technical tool of \emph{mixtures}, which allow sequences of $\B$-valued sets to be ``averaged'' into new ones. Using mixtures, one derives the \emph{maximum principle}, which allows existentially quantified statements to be instantiated without changing their truth-value (so is essentially the axiom of choice):
\begin{lstlisting}
lemma maximum_principle (ϕ : bSet 𝔹 → 𝔹)
(h_congr : B_ext ϕ) : ∃ u, (⨆(x:bSet 𝔹), ϕ x) = ϕ u
\end{lstlisting}
For example, if \lil{x : bSet 𝔹} and \lil{ϕ} is a \lil{𝔹}-valued predicate, if we have that \lil{⊤ ≤ ⨆ j : x.type, ϕ x}, there may not actually be some \lil{j : x.type} which attains that supremum. However, the maximum principle ensures that a witness can be constructed via mixtures.

 % TODO: expand, if we have room

After we verify the (shallow) statements of all the axioms in \lil{bSet 𝔹}, the last step is to construct a \(\mathbb{B}\)-valued \lil{L_ZFC}-structure, called \lil{V 𝔹}, on \lil{bSet 𝔹}, and check that the interpretations of the axioms are \(\top\). This amounts to proving that the deeply embedded statements correspond to the shallowly embedded statements. This is trivial for the axioms, since it is true by reflexivity, but takes more work for the axiom scheme of collection. This proves the following theorem.
\begin{lstlisting}
theorem fundamental_theorem_of_forcing :
  ⊤ ⊩[V 𝔹] ZFC
\end{lstlisting}
\subsection{Ordinals}
\begin{defn}\label{def:check}
  We define the canonical map \lil{check : pSet → bSet 𝔹} by
  \begin{lstlisting}
def check : pSet → bSet 𝔹
| ⟨α,A⟩ := ⟨α, check ∘ A, (λ a, ⊤)⟩
  \end{lstlisting}
  We write $\widecheck{x}$ for \lil{check x}, and call it a \emph{check-name}.
  % We call members of the image of \lil{check} \emph{check-names}, %\footnote{This terminology is standard, c.f. \cite{hamkins2012well, moore2019method}.}
  These are also known as \emph{canonical names}, as they are the canonical representation of standard two-valued sets inside a Boolean-valued model of set theory.\footnote{We were pleased to discover Lean's support for custom notation allowed us to declare the Unicode modifier character \texttt{U+030C} ($\widecheck{\hspace{1mm}}$) as a postfix operator for \texttt{check}.}
\end{defn}

In general, $\widecheck{x}$ might have different properties than $x$, but \(\Delta_0\) properties (i.e. those definable with only bounded quantification) are always preserved. Importantly, \lil{bSet 𝔹} thinks $\widecheck{\omega}$ is $\omega$. Notably, \lil{ω : pSet} is defined separately from \lil{ordinal.mk omega} (see below) to be the collection of all finite von Neumann ordinals indexed by recursion on $\mathbb{N}$, so the underlying types of \lil{ω : pSet} and \lil{ω : bSet 𝔹} are definitionally equal to \(\mathbb{N}\).

% \paragraph{Ordinals in \lil{bSet 𝔹}}\label{subpara:ordinals}
The treatment of ordinals in \lil{mathlib} associates a class of ordinals to every type universe, defined as isomorphism classes of well-ordered types. Lean's ordinals may be represented inside \lil{pSet} by defining a map \lil{ordinal.mk : ordinal → pSet} via transfinite recursion (indexing the von Neumann construction of ordinals). In pseudocode,
\begin{lstlisting}
def ordinal.mk : ordinal → pSet
| 0 := ∅
| succ ξ := pSet.succ (ordinal.mk ξ)
            -- i.e. (mk ξ ∪ {mk ξ})
| is_limit ξ := ⋃ η < ξ, (ordinal.mk η)
\end{lstlisting}
Working internally to any model \(M\) of \(\ZFC\), we can define the class \(\operatorname{Ord}(M)\) as the collection of transitive sets which are well-ordered by their membership relation. While \lil{ordinal.mk} actually induces an order-isomorphism of \lil{pSet}'s ordinals with Lean's ordinals, the map \[\text{\lil{check ∘ ordinal.mk : ordinal → bSet 𝔹}}\] generally fails to surject onto \lil{bSet 𝔹}'s ordinals (in general, these are mixtures of checked ordinals).
% To define ordinals, we can define a map \lil{ordinal.mk : ordinal → pSet} by transfinite recursion.
% If we compose this map with \lil{check} we get the ordinals in \lil{bSet 𝔹}.
% In particular, we get the least infinite ordinal \lil{ω : bSet 𝔹}, which witnesses the axiom of infinity.
% \lil{ω : pSet} is defined to be the collection of all finite von Neumann ordinals (via induction on $\mathbb{N}$), and we define \lil{ω : bSet 𝔹} as \(\widecheck{\omega}\).
% Now \lil{ω} is the $\subseteq$-least set that contains $\varnothing$ and is closed under the successor operation $x \mapsto x \cup \{x\}$.


We summarize the relationship between the three ``large'' types currently in play:
\[
  \begin{tikzcd}
    % & \text{\lstinline{Type u+1}} & & \\
    \texttt{pSet} \arrow{rr}{\texttt{check}} & & \texttt{bSet } \mathbb{B} & \\
    & & & \\
    \texttt{ordinal.\{u\}} \arrow{uu}{\texttt{ordinal.mk}} \arrow{uurr} & & & % \\
    % \hspace{0mm}  \arrow[dashed, no head]{rrr } & & & \hspace{0mm} \\
    % & \mathbb{B} & & \\
    % & \text{\lstinline{Type u}} & &
  \end{tikzcd}
\]

We adopt the convention to spell out the name of Lean ordinals and cardinals, and use (checked) Hebrew letters for their (Boolean-valued) set-theoretic counterparts, e.g.
\begin{lstlisting}
check (ordinal.mk (aleph 1)) = check (ℵ₁) = ℵ₁̌
\end{lstlisting}
% with respect to the above diagram, we have:
% \[
%   \begin{tikzcd}
%     % & \text{\lstinline{Type u+1}} & & \\
%     \aleph_1 \arrow[mapsto]{rr}{\texttt{check}} & & \widecheck{\aleph_1} & \\
%     & & & \\
%     \text{\lstinline{(aleph 1)}} \arrow[mapsto]{uu}{\texttt{ordinal.mk}} \arrow[mapsto]{uurr} & & & % \\
%     % \hspace{0mm}  \arrow[dashed, no head]{rrr } & & & \hspace{0mm} \\
%     % & \mathbb{B} & & \\
%     % & \text{\lstinline{Type u}} & &
%   \end{tikzcd}
% \]
We will freely conflate \lil{pSet} ordinals with their underlying types, so e.g. \(\nu : \aleph_2\) means \lil{ν : ℵ₂.type}. (It is always true that the cardinality of \lil{(ordinal.mk κ).type} is \lil{κ}.) Since in general, \(\widecheck{\aleph_1}\) is \emph{not} what \lil{bSet 𝔹} thinks is \(\aleph_1\), we will use a superscript, e.g. \(\aleph_k^{\mathbb{B}}\), to denote the internal alephs of \lil{bSet 𝔹}.

% TODO(jesse): add a note in the introduction on how Dana Scott was the first one to point out that the names could be taken at face value as a model of ZFC if one was willing to shift to a many-valued logic instead.


\section{Forcing} \label{sect:forcing}
Our point of departure from conventional accounts of forcing with a poset \(\mathbb{P}\) over a countable transitive model \cite{kunen2014set, jech2013set}, which use a generic filter to ``evaluate'' the \lstinline{ℙ}-names to produce an ordinary model of \(\ZFC\), is to force with \emph{Boolean-valued models} of \(\ZFC\) instead.
As first observed by Scott and Solovay \cite{scott-solovay}, this obviates the need for countable transitive models, generic filters, or the truth and definability lemmas, and allows us to work only with the \lstinline{𝔹}-names.
% Comment: this would be much better in the introduction: we need to motivate why we use boolean valued models.

The cost of taking the \lstinline{𝔹}-names at face value is that the calculus of the forcing relation \cite{shoenfield1971unramified}, a key technical tool in usual forcing arguments, is replaced by the calculation of Boolean truth-values in \lstinline{𝔹}.
From the Boolean-valued perspective, forcing a sentence \(\Phi\) in the language of \(\ZFC\) means constructing some Boolean algebra \lil{𝔹} and a \lil{𝔹}-valued model \(M\) of \(\ZFC\) such that the truth value \(\Phi^{M}\) of \(\Phi\) is \(\top\).
We will always force over a type universe \lil{Type u}, and our Boolean-valued models of \(\ZFC\) are always of the form \lil{bSet 𝔹} for some \lil{𝔹 : Type u}.
That \lil{𝔹} belongs to the ``ground model'' \lil{Type u} is crucial for forcing, as specific choices of \lil{𝔹} will affect the structure of \lil{bSet 𝔹} (and hence the truth-value of \(\Phi\)). % However, the effects of a particular choice of \lil{𝔹} is often only easily determined on the check-names, and a deeper combinatorial analysis of \lil{𝔹} is required to complete the argument.

In this section, we describe two forcing arguments, one for \(\neg \CH\) and another for \(\CH\).
Both follow roughly the same pattern. In both cases, we require the existence of a function; for \(\neg \CH\), an injection \(\aleph_2 \hookrightarrow \mathcal{P}(\omega)\), and for \(\CH\), a surjection \(\aleph_1 \twoheadrightarrow \mathcal{P}(\omega)\).
We will construct a Boolean algebra \lil{𝔹} which encodes the construction (in \lil{Type u}) of such a function \(F\).
Then \lil{𝔹} induces in \lil{bSet 𝔹} an approximation \(\widetilde{F}\) to such a function, which \emph{a priori} is only between check-names.
To finish the forcing argument, we must show that it suffices to work with \(\widetilde{F}\).
This requires a careful study of how truth-values are calculated in \lil{bSet 𝔹},
and ultimately reduces to an analysis of how truth-values of \(\forall\)-\(\exists\) statements in \lil{bSet 𝔹} can be \emph{reflected back} to \lil{Type u}, and a verification of a combinatorial condition on \lil{𝔹}.

\subsection{Regular open algebras}
\begin{defn}\label{def:regular-open-algebra}
  Let $X$ be a topological space, and for any open set $U$, let $U^{\perp}$ denote the complement of the closure of $U$.
  The \textbf{regular open algebra} of a topological space $X$, written $\operatorname{RO}(X)$, is the collection of all open sets $U$ such that $U = (U^\perp)^\perp$, or equivalently such that
  $U$ is equal to the interior of the closure of $U$.
  $\operatorname{RO}(X)$ is equipped with the structure of a complete Boolean algebra, with $x \sqcap y := x \cap y$ and $x \sqcup y := ((x \cup y)^\perp)^\perp$ and $\neg x := x^\perp$ and $\bigsqcup x_i := ((\bigcup x_i)^\perp)^\perp$.
\end{defn}

While forcing conditions usually present themselves as a poset instead of a complete Boolean algebra, any forcing poset can be represented as the dense suborder of a regular open algebra \cite{moore2019method}.

\begin{defn}\label{def:dense-suborder}
  A \textbf{dense suborder} of \(\B\) is a subset \(\mathbb{P} \subseteq \B\) satisfying the following conditions: (1) for all \(p \in \mathbb{P}\), \(\bot < p\); (2) for all \(\bot < b \in \B\), there exists a \(p \in \mathbb{P}\) such that \(p \leq b\).
\end{defn}

We will use the following combinatorial conditions on \(\mathbb{B}\) in our forcing arguments:

\begin{defn}\label{def:ccc}
We say that $\B$ has the \textbf{countable chain condition} (CCC) if every antichain $\mathcal{A} : I \to \B$ (i.e. an indexed collection of elements $\mathcal{A} = \{a_i\}_i$ such that whenever $i \neq j, a_i \sqcap a_j = \bot$) has a countable image.
\end{defn}

\begin{defn}\label{def:sigma-closed}
We say that \(\B\) is \textbf{\(\sigma\)-closed} if there exists a dense suborder \(\mathbb{P}\) of \(\B\) such that every \(\omega\)-indexed downwards chain \(p_0 \geq \cdots \geq p_n \cdots\) in \(\mathbb{P}\) has a lower bound \(p_{\omega}\) in \(\mathbb{P}\).
\end{defn}

\subsection{Cohen forcing}

As we have already seen in \Cref{def:powerset}, we construct the powerset of a \lil{𝔹}-valued set \lstinline{u : bSet 𝔹} using \lil{𝔹}-valued indicator functions \lil{χ : u.type → 𝔹}.
The basic strategy of Cohen forcing is to choose \lil{𝔹} such that for every \lil{ν : ℵ₂}, there is a canonical indicator function (a ``Cohen real'') \(\chi_{\nu} : \N \to \mathbb{B}\).
This is an external function (a member of a function type of \lstinline{Type u}) which descends to an injective function \(\widecheck{\aleph_2} \hookrightarrow \mathcal{P}(\omega)\) in \lil{bSet 𝔹}.

To show that the injection \(\widecheck{\aleph_2} \hookrightarrow \mathcal{P}(\omega)\)  suffices to negate \(\CH\), we will show that if \lil{𝔹} has the CCC, then \(\omega \prec \widecheck{\aleph_1} \prec \widecheck{\aleph_2}\), where $x\prec y$ means that there is no surjection from a subset of $x$ to $y$. We then ensure that \lil{𝔹} has this property by applying a powerful combinatorial argument called the \emph{\(\Delta\)-system lemma}.
% We also show that if \lil{𝔹} satisfies the CCC, then
% \(\omega \prec \widecheck{\aleph_1} \prec \widecheck{\aleph_2}\),
% where $x\prec y$ means that there is no surjection from a subset of $x$ to $y$.
% We ensure that our choice of \lil{𝔹} has this property, and together with the injection
% \(\widecheck{\aleph_2} \hookrightarrow \mathcal{P}(\omega)\) this suffices to negate \(\CH\).

\begin{defn}
  The \textbf{Cohen poset} for adding $\aleph_2$-many Cohen reals is the collection of all finite partial functions $\aleph_2 \times \mathbb{N} \to \mathbf{2}$, ordered by reverse inclusion.
\end{defn}

In the formalization, the Cohen poset is represented as a structure with three fields:
\begin{lstlisting}
structure ℙ_cohen : Type :=
  (ins : finset (ℵ₂.type × ℕ))
  (out : finset (ℵ₂.type × ℕ))
  (H : ins ∩ out = ∅)
\end{lstlisting}
%TODO(jesse): reword
That is, we identify a finite partial function \lil{f} with the triple \lil{⟨f.ins, f.out, f.H⟩}, where \lil{f.ins} is the preimage of $\{1\}$, \lil{f.out} is the preimage of $\{0\}$, and \lil{f.H} ensures that \lil{f} is well-defined.
While the members of the Cohen poset are usually defined as finite partial functions, we found that in practice \lil{f} is only needed to give a finite partial specification of a subset of $\aleph_2 \times \mathbb{N}$ (i.e. a finite set \lil{f.ins} which \emph{must} be in the subset, and a finite set \lil{f.out} which \emph{must not} be in the subset).
We chose this representation to make that information immediately accessible.

The Boolean algebra which we use for forcing $\neg\mathsf{CH}$ is
\[\mathbb{B}_{\mathsf{cohen}} := \operatorname{RO}(2^{\aleph_2 \times \mathbb{N}})\]
where we equip $2^{\aleph_2 \times \mathbb{N}}$ with the usual product space topology.

\begin{defn}
  We define the \textbf{canonical embedding} of the Cohen poset into \(\B_{\mathsf{cohen}}\) as follows:
\begin{lstlisting}
def ι : ℙ_cohen → 𝔹_cohen :=
λ p, {S | p.ins ⊆ S ∧ p.out ⊆ - S}
\end{lstlisting}
That is, we send each \(c : \mathbb{P}_{\mathsf{cohen}}\) to all subsets satisfying the specification given by \lil{c}. This is clopen, hence regular.
\end{defn}

Crucially, the image of this embedding is a dense suborder of \(\mathbb{B}_{\mathsf{cohen}}\).
This is essentially because the image of $\iota : \mathbb{P}_{\mathsf{cohen}} \to \B_{\mathsf{cohen}}$ \emph{is} the standard basis for the product topology.
Our chosen encoding of the Cohen poset also made it easier to perform this identification.

\begin{defn}\label{def:cohen-real}
  Let \(\nu : \aleph_2\). For any $n : \N$, the collection of all subsets of $\aleph_2 \times \N$ which contain $(\nu, n)$ is a regular open of $2^{\aleph_2 \times \N}$, denoted $\mathbf{P}_{(\nu, n)}$.
Thus, we associate to $\nu$ the $\B$-valued indicator function $\chi_{\nu} : \N \to \B$ defined by $\chi_{\nu}(n) := \mathbf{P}_{(\nu, n)}$.
  By \Cref{def:powerset}, each \(\chi_{\nu}\) induces a new $\B$-valued subset $\widetilde{\chi_{\nu}} \subseteq \widecheck{\N}$. We call $\widetilde{\chi_{\nu}}$ a \textbf{Cohen real}.
\end{defn}
\Cref{def:cohen-real} gives us an $\aleph_2$-indexed family of Cohen reals.
Converting this data into an injective function from \(\widecheck{\aleph_2}\) to $\mathcal{P}(\mathbb{N})$ inside \lil{bSet 𝔹} requires some care.
One must check that $\nu \mapsto \widetilde{\chi_{\nu}}$ is externally injective, and this is where the characterization of the Cohen poset as a dense subset of $\B$ (and moving back and forth between this representation and the definition as finite partial functions) comes in.
% Furthermore, one has to develop machinery similar to that for the powerset operation to convert an external injective function \lstinline{x.type → bSet 𝔹} to an internal injective function in \lstinline{bSet 𝔹}.
% Our custom tactics and automation for reasoning inside $\B$ made this latter task significantly easier than it would have been otherwise. We refer the interested reader to our formalization for details.

%By definition, our newly-constructed injection gives that \(\widecheck{\aleph_2} \preceq \mathcal{P}(\omega)\).
To finish negating \(\mathsf{CH}\), it suffices to show that \(\omega \prec \widecheck{\aleph_1} \prec \widecheck{\aleph_2}\),
i.e. that there is no surjection \(\widecheck{\omega} \twoheadrightarrow \widecheck{\aleph_1}\) and no surjection \(\widecheck{\aleph_1} \twoheadrightarrow \widecheck{\aleph_2}\).
We describe how we proved the latter claim; an identical argument can be used to show the former.

The strategy of the proof is to assume that there is a surjection \(\widecheck{\aleph_1} \twoheadrightarrow \widecheck{\aleph_2}\).
This surjectivity assumption is a Boolean-valued \(\forall\)-\(\exists\) statement about check-names, and we will \emph{reflect} it into the metatheory, producing a \(\forall\)-\(\exists\) statement about the non-checked counterparts in \lil{pSet}.
We will then use the CCC, a combinatorial condition on \(\B_{\mathsf{cohen}}\), to show that the reflected \(\forall\)-\(\exists\) statement implies a contradiction.

Specifically, we use the following lemma, which is true for general \(\mathbb{B}\):
\begin{lstlisting}
lemma AE_of_check_larger_than_check {x y : pSet}
  (f : bSet 𝔹) {Γ : 𝔹} (H_nonzero : ⊥ < Γ)
  (H : Γ ≤ is_surj_onto x̌ y̌ f) (Hy : ∃ z, z ∈ y) :
  ∀ i : y.type, ∃ j : x.type,
  ⊥ < is_func f ⊓ pair (x.func j)̌  (y.func i)̌  ∈ᴮ f
\end{lstlisting}
Suppose that there is a surjection \(\widecheck{\aleph_1} \twoheadrightarrow \widecheck{\aleph_2}\).
Applying this lemma to \(x := \widecheck{\aleph_1}\), \(y := \widecheck{\aleph_2}\), we obtain a \(\forall\)-\(\exists\) statement in the metatheory to which we can apply Lean's axiom of choice to produce a function \(g : \aleph_2 \to \aleph_1\).
Since externally, we know that \(\aleph_1 \prec \aleph_2\), it follows from the infinite pigeonhole principle that \(g\) must have an uncountable fiber over some \(\nu < \aleph_1\).
For every \(\eta \in g^{-1}(\{\nu\})\), let \(A_{\eta}\) be the element of \(\B_{\mathsf{cohen}}\) given by the lemma, i.e.
\[\text{\lil{(is_func f) ⊓ (pair (ℵ₁.func ν)̌  (ℵ₂.func η)̌  ∈ᴮ f)}}.\]
Because each \(A_{\eta}\) has as a conjunct the knowledge that \(f\) is a function, for \(\eta_1 \neq \eta_2\), \(A_{\eta_1}\) and \(A_{\eta_2}\) are incompatible, i.e. \(A_{\eta_1} \sqcap A_{\eta_2} = \bot\).
Since the lemma guarantees that each \(A_{\eta}\) is nonzero, the \(A_{\eta}\) form an uncountable antichain.
Therefore, if \(\mathbb{B}\) has the CCC, there is a contradiction. By \Cref{lemma:cohen-algebra-CCC}, \(\neg\mathsf{CH}\) is forced true in \(\text{\lil{bSet}}\ \mathbb{B}_{\mathsf{cohen}}\).

In our formalization, we actually prove a more general version of this argument, replacing \(\aleph_1\) and \(\aleph_2\) with any two infinite regular cardinals \(\kappa_1 < \kappa_2\).

\paragraph{CCC and the \(\Delta\)-system lemma}
To show that \(\B_{\mathsf{cohen}}\) has the CCC, we formalize and then apply a general result in transfinite combinatorics called the \emph{$\Delta$-system lemma}.
Though only briefly mentioned in \cite{DBLP:conf/itp/HanD19}, this was one of the most involved parts of our formalization of Cohen forcing, as it was a technical result in infinitary combinatorics, highlighting the robust library of cardinals and ordinals \texttt{mathlib}.
The details of the full argument are too technical to give here, so we omit the proofs in this section.
% Instead, we first give an elementary proof that \(\B_{\mathsf{cohen}}\) has the CCC, the key ideas of which are vastly generalized by the \(\Delta\)-system lemma (\Cref{lemma:delta-system-lemma:general}).

% \begin{proof}
% Given an antichain of regular opens, shrink them to basic clopens, which can then be identified with finite partial functions \((p_i : \aleph_2 \times \omega \to 2)_i\). Disjointness is equivalent to the finite partial functions all disagreeing with each other at some point. It suffices to show that for every \(n : \N\), there are only finitely many \(p_i\) of cardinality \(n\). It's easy to see this for \(n = 1\), and at the induction step, fix some \(p^*\); towards a contradiction, if there is an infinite family of cardinality \(n+1\), then we can use the pigeonhole principle to get an infinite subfamily \((q_i)\) which disagree with \(p^*\) at a point \(x\). Then the \((q_i)\) agree at \(x\), so \(x\) can be removed, contradicting the induction hypothesis.
% \end{proof}

%This style of argument can be refined to prove the far more general \(\Delta\)-system lemma; this is how it was implemented in our formalization.
A family $(A_i)_i$ of sets is called a \textbf{$\Delta$-system} if there is a set $r$, called the \textbf{root} such that whenever $i \ne j$ we have $A_i \cap A_j = r$.
We write $c^{<\kappa}$ for the supremum of $c^\rho$ for $\rho<\kappa$.

\begin{lemma}[\(\Delta\)-system lemma (Theorem 1.6, \cite{kunen2014set})]\label{lemma:delta-system-lemma:general}
  Let \(\kappa\) be an infinite cardinal and let \(\theta > \kappa\) be regular,
  such that for all \(\alpha < \theta$ we have $\alpha^{<\kappa} < \theta\).
  For any family \(\{A_i\}_{i\in I}\) such that \(|I| \geq \theta\) and for all \(i\), \(|A_i| < \kappa\),
  there is a subfamily of size \(\theta\) which forms a \(\Delta\)-system.
\end{lemma}
The formalization closely follows the proof given in Kunen \cite[Chapter 2, Theorem 1.6]{kunen2014set}.
The proof involves tricky reasoning steps involving ordinals, which are common in infinitary combinatorics.
It starts by assuming that without loss of generality $\bigcup_i A_i\subseteq\theta$, so that all the $A_i$ are well-ordered, and by assuming that all $A_i$ have the same order-type.
These simplifying assumptions are harder to formalize, because that involves actually proving the general case from the special case.
It also involves defining a sequence by transfinite recursion, while simultaneously proving that the sequence has certain properties (lies below $\theta$).

In the formalization, the fact that the type of ordinals is a large type, i.e.\ lives one universe level higher than the types it is built from, causes difficulties. (These difficulties were also present earlier, because whenever we use e.g. ``\lil{ℵ₂.type}'', we are actually referring to a nonconstructively chosen witness for the order type of all the ordinals less than \lil{aleph 2}.)
The reason is that the original proof heavily uses sets of ordinals, and taking their order types, but in Lean this would involve calculating in both \lstinline"ordinal.{u}" and \lstinline"ordinal.{u+1}".
Instead, we frequently work with well-orders of a given order type, instead sets of ordinals, to do all computations in \lstinline"ordinal.{u}".

Lastly, one must take care to formulate the $\Delta$-system so that $\{A_i\}_i$ is an indexed families, instead of a collections of sets.
\Cref{thm:product-ccc} below doesn't follow conveniently from the $\Delta$-system lemma if it is formulated with a collection of sets.
\cite{kunen2014set} is somewhat ambiguous which version is used.

Setting \(\kappa = \omega\) and \(\theta = \aleph_1\) in \Cref{lemma:delta-system-lemma:general} yields:
\begin{lemma}\label{lemma:delta-system-lemma:simple}
  Any uncountable family of finite sets has an uncountable subfamily forming a $\Delta$-system.
\end{lemma}
To apply this lemma to show that \(\B_{\mathsf{cohen}}\) has the CCC, we prove the following property about necessary and sufficient conditions for a product space to have the CCC. The proof can be found in \cite{DBLP:conf/itp/HanD19}.
We say that a topological space has the CCC if every family of pairwise disjoint open sets is countable.
\begin{thm}\label{thm:product-ccc}
  For any family $(X_i)_{i\in I}$ of topological spaces, $\prod_{i\in I} X_i$ has the CCC if for every finite $J\subseteq I$, the product $\prod_{i\in J} X_i$ has the CCC.
\end{thm}
From \Cref{thm:product-ccc} and the observation that $2^J$ has the CCC if $J$ is finite, the result follows.
\begin{lemma}\label{lemma:cohen-algebra-CCC}
  \(\B_{\mathsf{cohen}}\) has the CCC.
\end{lemma}

\subsection{Collapse forcing} \label{subsect:collapse}
% note(jesse, October 01 2019, 04:11 PM): i think levy collapse only involves the collapse of strongly inaccessible cardinals, and that the collapsing argument we use goes by the name of σ-closed, ω-closed, countably closed forcing or maybe just collapse forcing? we should clarify this.

Whereas Cohen forcing creates a new injection \(\widecheck{\aleph_2} \hookrightarrow \mathcal{P}(\omega)\), we can use \emph{collapse forcing} to create a new surjection \(F : \aleph_1^{\mathbb{B}} \twoheadrightarrow \mathcal{P}(\omega)\), where \(\aleph_1^{\mathbb{B}}\) denotes the ordinal that \lil{bSet 𝔹} thinks is $\aleph_1$.
Similarly to Cohen forcing, the strategy is to pick \lil{𝔹} such that there is a canonical \lil{𝔹}-valued indicator function on \(\widecheck{\aleph_1} \times \widecheck{\mathcal{P}(\omega)}\) representing the graph of a surjection \(\widetilde{F}\).
To show that \(\widetilde{F}\) suffices to force \(\CH\), we must verify that our choice of \(\mathbb{B}\) is \(\sigma\)-closed.
%

The formalization of collapse forcing is actually much more involved than the formalization of Cohen forcing. In Cohen forcing, we have to do relatively little work inside of \lil{bSet 𝔹} itself besides proving basic properties of functions. The difficulty is concentrated in proving and applying the CCC, which mostly happens in the metatheory. Moreover, constructing the new function (and the rest of the argument) required no density arguments at all. This is because in order to force \(\neg \CH\), we only had to ensure there was \emph{some} infinite cardinality between \(\omega\) and \(\mathcal{P}(\omega)\) (we did not determine exactly which internal aleph number \(\widecheck{\aleph_1}\) was in \lil{bSet 𝔹}).

However, to force \(\CH\), the quantifiers are flipped and now we must exclude \emph{all} cardinalities between \(\omega\) and \(\mathcal{P}(\omega)\). From cleverly choosing \(\mathbb{B}\), the best we will be able to do is to construct a surjection \(\pi : \widecheck{\aleph_1} \twoheadrightarrow \widecheck{\mathcal{P}(\omega)}\), and we are forced to prove that \(\widecheck{\aleph_1} = \aleph_1^{\mathbb{B}}\) and \(\widecheck{\mathcal{P}(\omega)} = \mathcal{P}(\omega)\). This means we must define and construct \(\aleph_1^{\mathbb{B}}\), entailing, for example, the development of the theory of ordinals internal to \lstinline{bSet 𝔹}. There are too many details like this to list, but we note that FOO (REPLACE ME) lines of code about the internal structure of \lstinline{bSet 𝔹} alone were added during the formalization of collapse forcing, compared to BAR (REPLACE ME) lines of code in the original development.

% \(\widecheck{\aleph_1} = \aleph_1^{\mathbb{B}}\), and that \(\widecheck{\mathcal{P}(\omega)} = \mathcal{P}(\omega).\)
% Both equalities follow from being able to lift functions \(\omega \to \widecheck{y}\) to functions \(\omega \to y\);
% this will follow from ensuring our choice of \(\mathbb{B}\) is \(\sigma\)-closed (\Cref{def:sigma-closed}).

\begin{defn}\label{def:collapse-poset}
  We define \(\mathbb{P}_{\mathsf{collapse}}\) to be the poset of countable partial functions \(\aleph_1 \to \mathcal{P}(\omega)\).
  The principal open sets
  \[D_p := \{g : \aleph_1 \to \mathcal{P}(\omega) \hspace{2mm} | \hspace{2mm} g \text{ extends } p\} , \hspace{3mm} p \in \mathbb{P}_{\mathsf{collapse}}\]
  form the basis of a topology \(\tau\) (finer than the product topology) on the function set \(\mathcal{P}(\omega)^{\aleph_1}\).
  We put
  \[\B_{\mathsf{collapse}} := \operatorname{RO}\left(\mathcal{P}(\omega)^{\aleph_1}, \tau\right).\]
\end{defn}

\begin{lemma}\label{lemma:collapse-algebra-sigma-closed}
  % Note to Floris: currently, sigma-closed is defined to be a property of complete Boolean algebras, namely that they possess a sigma-closed (in the usual sense) dense suborder
  \(\B_{\mathsf{collapse}}\) is \(\sigma\)-closed.
\end{lemma}

\begin{proof}
  We show that the collection of principal open sets \(\mathcal{D} := \{D_p\}_p\) forms a dense subset of
  \(\B_{\mathsf{collapse}}\) such that every $\omega$-indexed downwards chain in \(\mathcal{D}\) has a lower bound in \(\mathcal{D}\). Since \(\mathcal{D}\) generates the topology, it is clearly a dense suborder. For an arbitrary \(\omega\)-indexed downwards chain
  \[D_{p_0} \supseteq D_{p_1} \supseteq \cdots \supseteq D_{p_n} \supseteq \cdots,\]
  it follows from the definition of the principal open sets that $p_0 \subseteq p_1 \subseteq \cdots \subseteq p_n \subseteq \cdots$. Then put $p_\omega := \bigcup_i p_i$. Since the union of countable partial functions is a countable partial function, $D_{p_\omega}$ is a lower bound of $\{D_{p_i}\}_i$.
\end{proof}

\begin{remark}
  As an implementation detail, in the formalization we \emph{define} \(\mathbb{P}_{\mathsf{collapse}}\) to be the countable partial functions (in \lil{Type u}) between \lil{(ordinal.mk (aleph one) : pSet).type} and \lil{(powerset omega : pSet).type}, so that \\
  \(\mathbb{B}_{\mathsf{collapse}}\)-valued indicator functions on
  \begin{gather*}\text{\lil{ordinal.mk (aleph one) : pSet).type ×}}\\
   \text{\lil{(powerset omega : pSet).type}}
  \end{gather*}
  are definitionally equal to \(\mathbb{B}_{\mathsf{collapse}}\)-valued indicator functions on the underlying types of \lil{check (ordinal.mk (aleph one))} and \lil{check (powerset omega)}.
\end{remark}

To specify the surjection \(\widecheck{\aleph_1} \twoheadrightarrow \widecheck{\mathcal{P}(\omega)}\), we specify a subset (the graph of the function) of the powerset \(\mathcal{P}(\widecheck{\aleph_1} \times \widecheck{\mathcal{P}(\omega)})\).
In \(\text{\lil{bSet}}\ \mathbb{B}_{\mathsf{collapse}}\), we can do this by specifying the indicator function \(\chi_{\pi}\) of the graph of a function \(\pi : \widecheck{\aleph_1} \to \widecheck{\mathcal{P}(\omega)}\) as follows: to an \(\eta < \aleph_1\) and a subset \(S \subseteq \mathcal{P}(\omega)\) (in \lil{pSet}), we attach the \emph{principal open} (comprising functions extending the singleton countable partial function \(\{(\eta, S)\}\)):
\[
  \chi_\pi (\eta, S) := D_{\{(\eta, S)\}} = \{g : \aleph_1 \to \mathcal{P}(\omega) \operatorname{|} g (\eta) = S\}.
\]

More generally, we formalize conditions over generic \lil{x, y : pSet} and \lil{𝔹} for when a function \lil{af : x.type → y.type → 𝔹} induces a surjection \(\widecheck{x} \to \widecheck{y}\) in \lil{bSet 𝔹}.
By definition, such a function always induces a relation on the product (in \lil{bSet 𝔹}) of \lil{x} and \lil{y}.
Surjectivity is equivalent to \lil{⨅ j, (⨆ i, af i j) = ⊤}, totality is equivalent to \lil{⨅ i, (⨆ j, af i j) = ⊤}, and well-definedness follows from conditions:
\begin{lstlisting}
(∀ i, ∀ j₁ j₂, j₁ ≠ j₂ → af i j₁ ⊓ af i j₂ ≤ ⊥)
(∀ i₁ i₂, ⊥ < (func x i₁) =ᴮ (func x i₂) → i₁ = i₂)
\end{lstlisting}
Both surjectivity and totality of \(\chi_{\pi}\) require \emph{density arguments}, where the definition of indexed supremum (\(\bigsqcup x_i\)) in the regular open algebra as the regularization \(((\bigcup x_i)^\perp)^\perp\) of the set-theoretic union plays a key role: the union of the truth values is not the entire space, but is only a dense open whose regularization is the entire space. In particular, the density argument for surjectivity crucially uses that \(\aleph_1\) is uncountable while \(\omega\) is countable.

To finish demonstrating that \(\CH\) is true in \(\text{\lil{bSet}}\ \mathbb{B}_{\mathsf{collapse}}\), it remains to check that \(\widecheck{\mathcal{P}(\omega)} = \mathcal{P}(\omega)\) and \(\widecheck{\aleph_1} = \aleph_1^{\mathbb{B}}\).
There are two major obstacles. The first is that to even formally state the latter equality, we must construct \(\aleph_1^{\mathbb{B}}\) in \lil{bSet 𝔹}.
While the operation \lil{bv_powerset} (\Cref{def:powerset}) gives a construction of the internal powerset of any \lil{x : bSet 𝔹} (using \lil{𝔹}-valued indicator functions, for any \lil{𝔹}), \(\aleph_1^{\mathbb{B}}\) is only specified as the least ordinal greater than \(\omega\), and does not admit as direct a a construction.
We describe our construction of \(\aleph_1^{\mathbb{B}}\) (as the Hartogs number of \(\omega\)) in \Cref{subsect:forcing:aleph-1}.

Now we must ensure that no new countable ordinals are added to \(\aleph_1\) and that no new subsets of \(\omega\) are added to \(\mathcal{P}(\omega)\) in the passage via \lil{check} from \lil{pSet} to \lil{bSet 𝔹}.
We show this in \Cref{subsect:function-reflection} by proving that we can reflect functions with domain \(\omega\) from \lil{bSet 𝔹} to \lil{pSet}.

% As with Cohen forcing, we will proceed by using \(\forall\)-\(\exists\) reflection to reflect functions from \(\omega\) to check-names back into \lil{pSet}, and then showing that the two required equalities follow from this.

\subsection{Construction of \texorpdfstring{$\aleph_1$}{aleph 1}} \label{subsect:forcing:aleph-1}
Instead of using the specification of \(\aleph_1^{\mathbb{B}}\) as the least ordinal larger than \(\omega\) with Cantor's theorem and using the well-foundedness of the ordinals to construct \(\aleph_1\),
we opt for a direct construction of \(\aleph_1\), based on the well-known construction of \(\aleph_1\) as the \textbf{Hartogs number} of \(\omega\) \cite{hartogs1915problem}.

% TODO: summarize the construction of the Hartogs number

We lay out the basic strategy.
Recall that a term of type \lil{bSet 𝔹} comprises three pieces of information: an indexing type \(\alpha\), an indexing function \lil{A : α → bSet 𝔹}, and a truth-value function \lil{B : α → 𝔹}.
\begin{enumerate}
\item We \emph{define} the underlying type \(\alpha\) for \(\aleph_1^{\mathbb{B}}\) to be \lil{𝒫(ω × ω).type}.
\item We define the truth-value function \lil{B : α → 𝔹} to assign to any \(R \subseteq \omega \times \omega\) the (truth-value of) the sentence,
``there exists an ordinal \(\eta\) and an injection \(f : \eta \hookrightarrow \omega\) such that \(R\) is the image of the membership relation of \(\eta\) under \(f\).''

\item Using the maximum principle (which is essentially \(\mathsf{AC}\)), we define the indexing function \(A\) for \(\aleph_1^{\mathbb{B}}\) by choosing, for every \(R : \alpha\), a witness \(\eta_R\) such that \(R\) is the image of \(\eta\) under an injection into \(\omega\).
That \(A\) surjects onto countable ordinals reduces to the fact that order-isomorphic ordinals must be equal.
\end{enumerate}

\paragraph{Implementation details}
In the formalization, this strategy is implemented in three stages.
First, the axiom of comprehension (\Cref{def:comprehension}) is applied to \(\mathcal{P}(\omega \times \omega)\) to produce (what \lil{bSet 𝔹} thinks is) the collection of all relations \(R\) on \(\omega\) such that \(B(R)\) holds.
This combines steps \(1\) and \(2\) and produces a set \lil{a1'_aux}. Then we \emph{modify} the indexing function \lil{a1'_aux.func} (by using the maximum principle, as described in step \(3\)) to point from \(R\) to a chosen witness \(\eta_R\) for \(R\), producing \lil{a1'}.
Finally, since the ordinals \(0\) and \(1\) both have empty membership relations, it is unprovable in Lean whether \lil{a1'} contains one or the other, so we add both manually, producing \(\aleph_1^{\mathbb{B}}\).

Our implementation differs from the usual construction of Hartogs numbers by \emph{starting} with the sub-well-orders of \(\omega\), rather than taking the class of countable ordinals and showing this is actually a set by identification with sub-well-orders of \(\omega\). In this way we avoided performing a smallness argument, at the cost of using the axiom of choice to select witnesses. We remark that our construction does not use specific properties of \(\omega\) and easily generalizes to construct the successor cardinal of any infinite set. Instead of using membership \((<)\), we could have used subset \((\leq)\) instead, which would avoid the intermediate \lil{a1'}, but this would have made other parts of the proof more complex.

% TODO(jesse): maybe describe the interesting technical caveat about why external choice on the indexing types is not enough to finish the construction

\subsection{Function reflection} \label{subsect:function-reflection}

Suppose given \lil{y : pSet} and \lil{f : bSet 𝔹} such that \lil{bSet 𝔹} models that \lil{f} is a function from \(\omega\) to \(\widecheck{y}\).
We say that \lil{bSet 𝔹} \textbf{reflects \lil{f}} if there exists a \lil{g : pSet} such that \lil{g} is a function from \(\omega\) to \lil{y} in \lil{pSet}, and \lil{bSet 𝔹} models that \(\widecheck{g} = f\).
We say that \lil{bSet 𝔹} \textbf{reflects countable functions} if it reflects all such \lil{f}.
\begin{lemma}\label{lemma:function-reflect-suffices}
  Let \(\mathbb{B}\) be a complete Boolean algebra, and suppose that \lil{bSet 𝔹} reflects countable functions.
  Then \(\widecheck{\mathcal{P}(\omega)} = \mathcal{P}(\omega)\) and \(\widecheck{\aleph_1} = \aleph_1^{\mathbb{B}}\).
\end{lemma}
\begin{proof}
  % Observe that by definition of \(\aleph_1\), we have that for every ordinal \(\eta\), \(\eta < \aleph_1\) if and only if there exists a surjection \(\omega \twoheadrightarrow \eta\) (equivalently, there is an injection \(\eta \hookrightarrow \omega\)). Also, \(\mathcal{P}(\omega) \simeq \widecheck{2}^{\widecheck{\omega}}\) (in \(\mathsf{ZF}\)).

  To see that \(\widecheck{\aleph_1} \subseteq \aleph_1^{\mathbb{B}}\), let \(x\) be an arbitrary element of \(\widecheck{\aleph_1}\).
  By definition \(x\) is equal to \(\widecheck{\eta}\) for some \(\eta < \aleph_1\) in \lil{pSet}.
  Since the ordinals and cardinals of \lil{pSet} are isomorphic to Lean's ordinals and cardinals for \lil{Type u}, \(\eta\) injects into \(\omega\) (in \lil{pSet}, and also at the level of indexing types).
  Since being an injective function is \(\Delta_0\), it is absolute for \lil{check}, so \(x = \widecheck{\eta}\) injects into \(\omega\).
  Then, by definition of \(\aleph_1^{\mathbb{B}}\) we have \(x \in \aleph_1^{\mathbb{B}}\).\footnote{Note that this did not use our assumption, and holds for general \(\mathbb{B}\).
  For a conventional proof in a set-theoretic metatheory, see e.g. \cite{bell2011set}}

  To see that \(\aleph_1^{\mathbb{B}} \subseteq \widecheck{\aleph_1}\), suppose towards a contradiction that this is not true; since the ordinals are well-ordered,
  this means that \(\widecheck{\aleph_1} < \aleph_1^{\mathbb{B}}\), so by definition of \(\aleph_1^{\mathbb{B}}\), there is a surjection \(f : \omega \to \widecheck{\aleph_1}\).
  By assumption, this surjection can be lifted to a function \(g : \omega \to \aleph_1\) in \lil{pSet}, which can again be checked to be surjective, a contradiction.

  Similarly, it is true for general \(\mathbb{B}\) and any \lil{x : pSet} that \(\widecheck{\mathcal{P}(x)} \subseteq \mathcal{P}(\widecheck{x})\),
  because indicator functions into \lil{bool} naturally induce indicator functions to \(\mathbb{B}\) (by composing with the canonical inclusion \lil{bool → 𝔹}).
  Conversely, to show that \(\mathcal{P}(\omega) \subseteq \widecheck{\mathcal{P}(\omega)}\), use the isomorphism \(\mathcal{P}(\omega) \simeq \widecheck{2}^{\widecheck{\omega}}\) to reduce this to showing that \(\widecheck{2}^{\widecheck{\omega}} \subseteq \widecheck{2^{\omega}}\),
  and then apply the assumption to an arbitrary element of \(\widecheck{2}^{\widecheck{\omega}}\).
\end{proof}

It remains to show that \(\mathbb{B}_{\mathsf{collapse}}\) fulfills the assumptions of \Cref{lemma:function-reflect-suffices}.

\begin{lemma}\label{lemma:function-reflect}
  \(\text{\lil{bSet}}\ \mathbb{B}_{\mathsf{collapse}}\) reflects countable functions.
\end{lemma}

% \subsection{Reflecting Boolean-valued \(\forall\)-\(\exists\) statements into the metatheory} \label{subsect:reflect}

\begin{proof}
  Fix \(y\) and \(f\). It suffices to show that
\begin{lstlisting}
f ∈ᴮ functions ω y̌
  ≤ ⨆ (g : bSet 𝔹),
      g ∈ᴮ (functions omega y)̌  ⊓ g =ᴮ f
\end{lstlisting}
  and by a density argument, it suffices to show that for every principal open \(D_p\), for \(D := D_p \cap f \in^{\B} \mathsf{functions}\ \omega \ \widecheck{y}\),
\begin{lstlisting}
⊥ < (⋃ g, D ⊓ g ∈ᴮ (functions omega y)̌  ⊓ g =ᴮ f)
\end{lstlisting}
  It suffices to construct a single function \(g : \omega \to y\) such that \(\bot < D \sqcap \widecheck{g} = f\).
  As with Cohen forcing, we will reflect a Boolean-valued \(\forall\)-\(\exists\) statement into the metatheory, and then use a combinatorial property of \(\mathbb{B}_{\mathsf{collapse}}\) to strengthen it.
  The following lemma is true for general \(\mathbb{B}\):
\begin{lstlisting}
lemma AE_of_check_func_check (x y : pSet)
  {f : bSet 𝔹} {Γ : 𝔹}
  (H : Γ ≤ is_func' x̌ y̌ f) (H_nonzero : ⊥ < Γ) :
  Π (i : x.type), ∃ (j : y.type) (Γ' : 𝔹)
  (H_nonzero' : ⊥ < Γ') (H_le : Γ' ≤ Γ),
  Γ' ≤ (is_func' x̌ y̌ f) ∧
  Γ' ≤ (pair (x.func i)̌  (y.func j)̌ ) ∈ᴮ f
\end{lstlisting}
Recursively applying this lemma, we obtain \(g_0, \dots, g_n, \dots\) such that

\[D \sqcap (0 , g_0) \in^{\mathbb{B}} f > \cdots > D \sqcap \left(\bigsqcap_{k \leq n} ((k, g_k) \in^{\mathbb{B}} f)\right) > \cdots > \bot. \]

The intersection of this chain implies that \(g := \{(k, g_k)\}_{k \in \omega}\) is the required lift of \(f\).
For general \(\mathbb{B}\), this intersection might be \(\bot\), but because \(\mathbb{B}_{\mathsf{collapse}}\) is \(\sigma\)-closed,
we can shrink each term of the above chain into a dense suborder \(\mathcal{D}\) such that all downward \(\omega\)-indexed chains in \(\mathcal{D}\) have nonzero intersection, so the intersection of the chain is indeed nonzero.
\end{proof}

Implementing this argument was one of the most technical parts of our formalization. At each step of the construction of the downwards chain, we must recursively apply a \(\forall\)-\(\exists\) statement and use the axiom of choice to select two witnesses (with four side conditions), which are then used to simultaneously construct the downwards chain and the function \lstinline{g : pSet}. This was implemented as a monolithic recursive function defined using Lean's equation compiler, with the required parts separated afterwards.

% partial functions in Lean, introduce the collapsing boolean algebra, show omega-closedness.

% Construction of $\aleph_1$.

\subsection{The independence of CH} \label{subsect:forcing:independence}

In \Cref{subsect:bset:fundamental-thm} we showed that \lil{bSet 𝔹} is a model \lil{ZFC},
which means that we can interpret the deeply-embedded statement of \lil{CH_formula} into
\lil{bSet 𝔹}.
We now verify that the deeply-embedded interpretations of \lil{CH_formula} coincide with the shallow interpretations of \(\mathsf{CH}\).

As we have already observed, an easy consequence of Boolean-valued soundness is that a formula is unprovable if its negation has a model. Thus, we have:
\begin{lstlisting}
lemma unprovable_of_model_neg {T : Theory L} {f : sentence L} (S : bStructure L 𝔹)
  (H_model : ⊤ ⊩[S] T) [H_nonempty : nonempty S]
  {Γ : 𝔹} (H_nonzero : (⊥ : 𝔹) < Γ)
  (H : Γ ⊩[S] ∼f) : ¬ (T ⊢' f)

lemma V_𝔹_cohen_models_neg_CH :
  ⊤ ⊩[V 𝔹_cohen] ∼CH_formula
lemma V_𝔹_collapse_models_CH :
  ⊤ ⊩[V 𝔹_collapse] CH_formula
\end{lstlisting}
\noindent Combining these results yields
\begin{lstlisting}
theorem CH_unprv : ¬ (ZFC ⊢' CH_formula)
theorem neg_CH_unprv : ¬ (ZFC ⊢' ∼CH_formula)
\end{lstlisting}
\noindent and the independence of CH follows.
\begin{lstlisting}
def independent (T : Theory L) (f : sentence L) : Prop :=
¬ T ⊢' f ∧ ¬ T ⊢' ∼f
theorem independence_of_CH : independent ZFC CH_f :=
by finish [independent, CH_unprv, neg_CH_unprv]
\end{lstlisting}
\section{Automation and metaprogramming}
\label{sect:metaprogramming}

A key feature of Lean is that it is its own metalanguage \cite{Ebner:2017:MFF:3136534.3110278}, allowing for seamless in-line definitions of custom tactics (and modifications of existing ones).
This feature was an invaluable asset, as it allowed the rapid development of a custom tactic library for simulating natural-deduction style proofs in complete Boolean algebras (\Cref{subsect:natded}) and automating equality reasoning in those proofs (\Cref{subsect:bv-cc}).

\subsection{Simulating natural deduction proofs in \texorpdfstring{\(\mathbb{B}\)}{B}} \label{subsect:natded}
As stressed by Scott \cite{scott2008algebraic}, ``A main point ... is that the well-known algebraic characterizations of [complete Heyting algebras] and [complete Boolean algebras] exactly mimic the rules of deduction in the respective logics.''
Indeed, that is really why the Boolean-valued soundness theorem (see \Cref{boolean-soundness}) is true. One thinks of the \lil{≤} symbol in an inequality of Boolean truth-values as a turnstile in a proof state:
the conjuncts on the left as a list of assumptions in context, and the quantity on the right as the goal.
For example, given \lil{a b : 𝔹}, the identity $(a \Rightarrow b) \sqcap a \leq b$ could be proven by unfolding the definition of material implication, but it is really just modus ponens;
similarly, given an indexed family \lil{a : I → 𝔹}, the equivalence \lstinline{(⨆i, a i ≤ b) ↔ ∀ i, a i ≤ b} is just $\exists$-elimination.

Difficulties arise when the statements to be proved become only slightly more complicated. Consider the following example, which should be  ``\lil{by assumption}'':
\begin{lstlisting}
∀ a b c d e f g : 𝔹,
  (d ⊓ e) ⊓ (f ⊓ g ⊓ ((b ⊓ a) ⊓ c)) ≤ a
\end{lstlisting}
or slightly less trivially, the following example where the goal is attainable by ``implication introduction and \emph{modus ponens}''
\begin{lstlisting}
(a ⟹ b) ⊓ (b ⟹ c) ≤ a ⟹ c
\end{lstlisting}
In this last example, even if one has a lemma which concludes \lil{a ⟹ b ⊓ a ≤ b}, one must perform tedious reasoning modulo the associativity and commutativity of \(\sqcap\) to apply it.
Our solution is to piggyback on top of the tactic monad's AC-invariant handling of hypotheses in the tactic state, by applying the \textbf{Yoneda lemma} for posets:
\label{poset-yoneda}
\begin{lstlisting}
lemma poset_yoneda {β} [partial_order β] {a b : β}
  (H : ∀ Γ : β, Γ ≤ a → Γ ≤ b) : a ≤ b
\end{lstlisting}
With a little custom automation, our first example nearly becomes ``\lil{by assumption}''
\begin{lstlisting}
example {a b c d e f g : 𝔹} :
  (d ⊓ e) ⊓ (f ⊓ g ⊓ ((b ⊓ a) ⊓ c)) ≤ a :=
by { tidy_context, assumption }
/-  Goal state before `assumption`:
  [...]
  H_right_right_left_left : Γ ≤ b,
  H_right_right_left_right : Γ ≤ a
  ⊢ Γ ≤ a  -/
\end{lstlisting}
Above, \lil{tidy_context} combines an application of \lil{poset_yoneda} with a call to the simplifier to split hypotheses of the form \lstinline{Γ ≤ a₁ ⊓ a₂ ⊓ ... aₙ} into \lstinline{Γ ≤ a₁, Γ ≤ a₂, ..., Γ ≤ aₙ}.
% Compare this with a more conventional proof, where we even have the deduction theorem and modus ponens available as lemmas: % cut?
% \begin{lstlisting}
% example {β : Type*} [complete_boolean_algebra β]
%   {a b c : β} :
%  ( a ⟹ b ) ⊓ ( b ⟹ c ) ≤ a ⟹ c :=
% begin
%   rw [ ← deduction, inf_comm, ← inf_assoc ],
%   transitivity b ⊓ (b ⟹ c),
%     { refine le_inf _ _,
%       { apply inf_le_left_of_le, rw inf_comm,
%         apply mp },
%       { apply inf_le_right_of_le, refl }},
%     { rw inf_comm, apply mp }
% end
% \end{lstlisting}
One use-case where automation is crucial is context specialization.
For example, suppose that after preprocessing with \lstinline{poset_yoneda}, the goal is \lstinline{Γ ≤ (a ⟹ b)}, and one would like to apply implication introduction,
adding \lstinline{Γ ≤ a} to the context and reducing the goal to \lstinline{Γ ≤ b}. However, the deduction theorem only lets us rewrite the goal to \lstinline{Γ ⊓ a ≤ b}, and we can only add \lstinline{Γ ⊓ a ≤ a} to the context.
So we can introduce the implication after all, but at the cost of specializing the context \lstinline{Γ} to the smaller context \lstinline{Γ' := Γ ⊓ a}.
But now, in order for the user to continue the pretense that they are merely doing first-order logic, this change of variables must be propagated to the rest of the assumptions% which may still be of the form \lstinline{Γ ≤ _}
---which is extremely tedious to do by hand, but easy to automate.
This is done by the tactic \lil{bv_imp_intro}, as in the following example (note also the use of custom coercions to turn \(\B\)-valued implications into \lil{Π}-types).
\begin{lstlisting}
example {a b c : 𝔹} :
  (a ⟹ b) ⊓ (b ⟹ c) ≤ a ⟹ c :=
  by { tidy_context, bv_imp_intro Ha,
        exact a_1_right (a_1_left Ha) }
\end{lstlisting}

It would have been possible to go further and even write a custom tactic state,
as was done for temporal logic in Unit-B \cite{Hudon2015TheUM} or for Lean's SMT-mode framework,
such that the machinery for handling the ambient context \(\Gamma\) is completely hidden and the Boolean-valued tactics receive their own namespace.
However, we felt the benefits of doing so in our formalization would have been mostly cosmetic, and we leave more sophisticated implementations for future work.

\subsection{Boolean-valued equality reasoning}

\paragraph{Congruence closure on quotient types} \label{subsect:bv-cc}
Another benefit of applying \hyperref[poset-yoneda]{\lstinline{poset_yoneda}} and using context variables \(\Gamma\) throughout the formalization is that this approach exposes a canonical family of setoids on \lil{bSet 𝔹} induced by \lil{𝔹}-valued equality:
for every \(\Gamma : \mathbb{B}\) the relation \(\lambda\; x \; y, \Gamma \leq x =^{\mathbb{B}} y\) is an equivalence relation on \lil{bSet 𝔹} (the larger \(\Gamma\) is, the finer the equivalence relation).

Since Lean natively supports quotient types, then as soon as e.g. all (Boolean-valued) existentials have been split and the only task remaining is to perform equality reasoning,
we can quotient by the appropriate setoid and simply call \lil{cc};
this is easy to automate with a custom tactic \lil{bv_cc}. % cut?
% \begin{lstlisting}
% example {x y z x₁ y₁ z₁ : bSet 𝔹} {Γ : 𝔹}
%   (H1 : Γ ≤ x =ᴮ y) (H2 : Γ ≤ y =ᴮ z)
%   (H3 : Γ ≤ z =ᴮ z₁) (H4 : Γ ≤ z₁ =ᴮ y₁)
%   (H5 : Γ ≤ y₁ =ᴮ x₁) : Γ ≤ x =ᴮ x₁ := by bv_cc
% \end{lstlisting}
We can add support for any predicate satisfying an appropriate \(\mathbb{B}\)-valued congruence lemma,
although we do not have a way of handling such extensions uniformly and currently add support for individual predicates by hand:
\begin{lstlisting}
example {x₁ y₁ x₂ y₂ : bSet 𝔹} {Γ}
  (H₁ : Γ ≤ x₁ ∈ᴮ y₁) (H₂ : Γ ≤ x₁ =ᴮ x₂)
  (H₂ : Γ ≤ y₁ =ᴮ y₂) : Γ ≤ x₂ ∈ᴮ y₂ := by bv_cc
\end{lstlisting}
\paragraph{Discharging congruence lemmas via \texttt{simp}} \label{subsect:B-ext}
Rewriting along \(\mathbb{B}\)-valued equality is the same as rewriting in the appropriate setoid parametrized by the current context \(\Gamma\), % cut? entire paragraph
so that the motive must satisfy an appropriate \emph{congruence lemma} \lil{h_congr} with respect to the equivalence relation:
\begin{lstlisting}
lemma bv_rw {x y : bSet 𝔹} {Γ : 𝔹}
  (H : Γ ≤ x =ᴮ y) {ϕ : bSet 𝔹 → 𝔹}
  {h_congr : ∀ x y, x =ᴮ y ⊓ ϕ x ≤ ϕ y}
  {H_new : Γ ≤ ϕ y} : Γ ≤ ϕ x
\end{lstlisting}
We alias the type of \lil{h_congr}, and add a database of \lil{@[simp]} lemmas expressing that congruence lemmas are preserved by first-order logical operations:
\begin{lstlisting}
def B_ext (ϕ : bSet 𝔹 → 𝔹) : Prop :=
∀ x y, x =ᴮ y ⊓ ϕ x ≤ ϕ y
@[simp] lemma B_ext_infi {ι} {ϕ : ι → (bSet 𝔹 → 𝔹)}
  {h : ∀ i, B_ext (ϕ i)} : B_ext (λ x, ⨅i, ϕ i x)
\end{lstlisting}
Furthermore, \lil{simp} is able to handle recursive applications of these lemmas on its own, allowing most congruence lemma proof obligations to be automatically discharged:
\begin{lstlisting}
example {w : bSet 𝔹} :
  (let ϕ := λ x, ⨅ z, z ∈ᴮ w ⊓ z ⊆ᴮ x ⊓ x ⊆ᴮ z
  in B_ext ϕ) := by simp
\end{lstlisting}
% \section{Related Work}
% \label{sect:related-work}
% Compare with other formalization on the consistency of CH. % do there exist any?
\section{Conclusions and future work}
\label{sect:conclusions}
% This paper describes a successful completion of the Flypitch project, giving the first formalization of the independence of the continuum hypothesis.
% This problem is problem 24 on Wiedijk's list ``Formalizing 100 theorems''~\cite{wiedijk100theorems},
% and this is the 95-th formalized result of that list.

Interestingly, we never used transfinite recursion for developing elementary set theory in \lil{pSet} and \lil{bSet 𝔹}. Indeed, the prevalence of transfinite recursion in traditional presentations of set theory is only a consequence of the use of transfinite recursion in the traditional definitions of \(V\) and \(V^{\mathbb{B}}\). By instead encoding \(V\) and \(V^{\mathbb{B}}\) as inductive types which expose \(\in\)-induction as their native induction principle, we completely eliminate transfinite induction this part of our formalization. % cut?

% talk about L
Our consistency proof of \(\CH\) is very different from the traditional proof, due to G\"odel, which shows that the constructible universe \(\mathsf{L}\) satisfies \(\mathsf{GCH}\). An obvious path to constructing \(\mathsf{L}\) is to define the definable powerset operation with an inductive predicate on \lil{pSet} whose constructors encode the nine G\"odel operations, and to then build the constructible hierarchy by transfinite recursion. It is interesting to consider whether there is a definition of \(\mathsf{L}\) in the same spirit as \lil{pSet} which completely avoids transfinite induction.

We also want to formalize the conservativity of \(\mathsf{ZFC}\) over the usual presentation in the language \(\{\in\}\), by proving more generally that extending a language with definable function symbols is conservative.
Furthermore, while formulas with de Bruijn indices enjoy pleasant theoretical properties, they are difficult to write and debug by hand. It should be possible with Lean's metaprogramming to write a custom parser from formulas with named variables.

% talk about proof transfer using the completeness theorem
% talk about how metaprogramming is really kind of a hack to replay proofs
% talk about proof transfer from mm0
% should have uniform way to treat Δ₀ proof transfer by _reflection_
% more intelligent way of handling congruence lemmas
While our custom automation saved a considerable amount of work, much of it is only an approximation to a more principled approach by \emph{reflection}. The natural deduction and equality reasoning tactics in \Cref{subsect:natded} and \Cref{subsect:bv-cc} make it easier to manually replay a first-order proof of a theorem of \(\ZFC\) in \lil{bSet 𝔹}, but the Boolean-valued soundness theorem automatically performs this replay for a deeply-embedded first-order proof tree. Ideally, automation would reify a \(\mathbb{B}\)-valued goal to the corresponding first-order statement, discharge it by an ATP, encode the solution in our deeply-embedded proof system, then apply soundness. Alternately, one could perform proof transfer via the completeness theorem. If a goal only requires first-order reasoning in \(\ZFC\), then one can prove it in an arbitrary ordinary model of \(\ZFC\) (where the additional complexity of \(\mathbb{B}\)-valued semantics is hidden from Lean's automation), apply the completeness theorem to produce a first-order proof tree, then replay it with soundness. The advantage to this approach is that a proof would only be computed once, then reused in any model, ordinary or \(\mathbb{B}\)-valued, whereas in our formalization, we occasionally had to prove the same statement separately in \lil{pSet} and \lil{bSet 𝔹}.



% Similarly, although we know that \(\Delta_0\) properties are preserved by \lil{check}, we do not handle this uniformly and only prove instances of this theorem by hand. However, a human mathematician proves this with a single ``tactic'' which reifies a \(\mathbb{B}\)-valued goal to a first-order formula, and then computes that all quantifiers are bounded.
% For example, a human mathematician would provide the congruence lemmas automatically discharged in \Cref{subsect:B-ext} by reifying a \(\mathbb{B}\)-valued goal to a first-order formula and applying a theorem

% \subsection{Future Work}

% TODO(jesse): polish

% This formalization consists of a reusable library which can be used for future formalizations in first-order logic, model theory and set theory.
% We have just scratched the surface of modern set theory with this formalization, and it would be interesting to formalize some more modern results.
% In this section we will focus only on results directly related to the results in our paper.

% In this paper we used \(\sigma\)-closed forcing to show the consistency of $\CH$.
% It would be interesting to formalize the construction of $L$, the constructible hierarchy. In $L$ the generalized continuum hypothesis $\mathsf{GCH}$ also holds, which states that $2^{\aleph_\alpha}=\aleph_{\alpha+1}$ for all ordinals $\alpha$.

Besides the construction of \(\mathsf{L}\), the consistency of $\mathsf{GCH}$ can also be shown by an iterated forcing argument. Our current implementation of forcing should extend without too much difficulty to iterated forcing with Boolean-valued models.  % There are also many generalizations of the consistency of $\neg \mathsf{CH}$.
% We could generalize it to the consistency of $\mathfrak{c}=\aleph_\alpha$, for any cardinal $\aleph_\alpha$ with uncountable cofinality.
% Or more generally, we could formalize
An interesting challenge could be Easton's theorem, which states that on regular cardinals the function $\kappa\mapsto 2^\kappa$ can be any monotone function that doesn't contradicts K\"onig's Theorem ($\kappa<\cf(2^\kappa)$)~\cite{easton1970powers}.

Our work only marks the beginning of an integration of formal methods with modern set theory. Since Cohen, increasingly sophisticated forcing arguments have been used to produce a vast hierarchy of independence and relative consistency results. The challenge to proof engineers is to develop libraries and automation that can uniformly handle them, so that the manipulation of forcing notions and forcing extensions in a proof assistant becomes as routine as manipulating objects in an algebraic hierarchy is today. One place to start would be to develop a good interface for forcing with posets and for transferring arguments along the equivalence to Boolean-valued models. One could develop a typeclass hierarchy of combinatorial conditions on forcing notions, and similarly for the relative consistency strengths of extensions to \(\ZFC\).
As the next challenge to formalizers, we propose the classical result of Shelah \cite{shelah1974infinite} on the independence of Whitehead's problem, the proof of which combines the consistency of the axiom of constructibility with the consistency of Martin's axiom over \(\ZFC + \neg \CH\) \cite{martin1970internal} to resolve a conjecture in abstract algebra.

% We believe that many classic theorems in set theory are within reach% , such as Easton's theorem (\cite{easton1970powers})



% such as the independence of Suslin's hypothesis \cite{foo}, Solovay's theorem on measurable subsets of \(\mathbb{R}\) \cite{bar},

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  We thank the members of the CMU-Pitt Lean group, particularly Simon Hudon, Jeremy Avigad, Mario Carneiro, Reid Barton, and Tom Hales for their feedback and suggestions; we are also grateful to Dana Scott and John Bell for their advice and correspondence.

  The authors gratefully acknowlege the support by the
  \grantsponsor{GS100000001}{Alfred P. Sloan Foundation}{https://doi.org/10.1038/201765d0}, Grant
  No.~\grantnum{GS100000001}{G-2018-10067}.
\end{acks}

%% Bibliography
\bibliography{flypitch-cpp}

%% Appendix
% \appendix
% \section{Appendix}

% Text of appendix \ldots

\end{document}
